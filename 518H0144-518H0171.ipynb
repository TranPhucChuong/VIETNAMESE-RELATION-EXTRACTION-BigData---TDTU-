{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR3SDsrjxpPc",
        "outputId": "e17d8204-111e-4dec-e539-3771633230e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.14.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7dcipM8zTga",
        "outputId": "dd6351fa-c295-49a4-b1cf-8518405680b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: underthesea in /usr/local/lib/python3.7/dist-packages (1.3.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.1.0)\n",
            "Requirement already satisfied: transformers>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (4.14.1)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.0.1)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from underthesea) (6.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.10.0+cu111)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.2.5)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from underthesea) (0.9.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from underthesea) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from underthesea) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->underthesea) (3.10.0.2)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.5.0->underthesea) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.5.0->underthesea) (4.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.5.0->underthesea) (0.2.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.5.0->underthesea) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.5.0->underthesea) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.5.0->underthesea) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.5.0->underthesea) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.5.0->underthesea) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=3.5.0->underthesea) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.5.0->underthesea) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->underthesea) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install underthesea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i01n6zl00DYp"
      },
      "outputs": [],
      "source": [
        "from underthesea import sent_tokenize, word_tokenize\n",
        "import time\n",
        "import copy, json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plot\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "jSbUoKxORjhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfyCca4w0dw-",
        "outputId": "6881dd8d-e90c-4e8d-82a0-4545f8edc9d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "{'doc_id': '23351113', 'sent_id': 1, 'sentence': 'Ảnh minh họa Thứ trưởng Bộ GD&ĐT Nguyễn Thị Nghĩa đã có ý kiến về vấn đề này.', 'spos': [311, 388], 'entity_1': {'text': 'Bộ GD&ĐT', 'pos': [24, 32]}, 'entity_2': {'text': 'Nguyễn Thị Nghĩa', 'pos': [33, 49]}, 'label': 'AFFILIATION'}\n",
            "{'doc_id': '23351113', 'sent_id': 2, 'sentence': 'Ông Nguyễn Tùng Lâm Sắp tới, Bộ GD&ĐT sẽ tăng cường thanh, kiểm tra để có biện pháp chấn chỉnh việc thực hiện quy định Điều lệ của Ban đại diện cha mẹ học sinh.', 'spos': [894, 1054], 'entity_1': {'text': 'Nguyễn Tùng Lâm', 'pos': [4, 19]}, 'entity_2': {'text': 'Bộ GD&ĐT', 'pos': [29, 37]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351113', 'sent_id': 3, 'sentence': 'Cũng theo Thứ trưởng Nguyễn Thị Nghĩa , trước những biến tướng như hiện tại, Bộ GD&ĐT nghiên cứu có thể bỏ quy định này để tránh hiện tượng lách luật.', 'spos': [1220, 1370], 'entity_1': {'text': 'Nguyễn Thị Nghĩa', 'pos': [21, 37]}, 'entity_2': {'text': 'Bộ GD&ĐT', 'pos': [77, 85]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351113', 'sent_id': 4, 'sentence': 'Liên quan đến vấn đề lãnh đạo ngành Giáo dục trao đổi, thầy Nguyễn Văn Định – Hiệu trưởng Trường THPT Phú Điền , Đồng Tháp – chia sẻ:', 'spos': [1371, 1504], 'entity_1': {'text': 'Nguyễn Văn Định', 'pos': [60, 75]}, 'entity_2': {'text': 'Trường THPT Phú Điền', 'pos': [90, 110]}, 'label': 'AFFILIATION'}\n",
            "{'doc_id': '23351113', 'sent_id': 5, 'sentence': 'Liên quan đến vấn đề lãnh đạo ngành Giáo dục trao đổi, thầy Nguyễn Văn Định – Hiệu trưởng Trường THPT Phú Điền , Đồng Tháp – chia sẻ:', 'spos': [1371, 1504], 'entity_1': {'text': 'Nguyễn Văn Định', 'pos': [60, 75]}, 'entity_2': {'text': 'Đồng Tháp', 'pos': [113, 122]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351113', 'sent_id': 6, 'sentence': 'Liên quan đến vấn đề lãnh đạo ngành Giáo dục trao đổi, thầy Nguyễn Văn Định – Hiệu trưởng Trường THPT Phú Điền , Đồng Tháp – chia sẻ:', 'spos': [1371, 1504], 'entity_1': {'text': 'Trường THPT Phú Điền', 'pos': [90, 110]}, 'entity_2': {'text': 'Đồng Tháp', 'pos': [113, 122]}, 'label': 'LOCATED'}\n"
          ]
        }
      ],
      "source": [
        "with open('train_data.json') as train_data_json:\n",
        "  jtrain_data = json.load(train_data_json)\n",
        "\n",
        "print(type(jtrain_data))\n",
        "print(*jtrain_data[0:6], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FILl2USP0kyz",
        "outputId": "d58394be-b59c-46e0-acca-78cf8e42ca51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "{'doc_id': '23351996', 'sent_id': 1, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351996', 'sent_id': 2, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351996', 'sent_id': 3, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351996', 'sent_id': 4, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351996', 'sent_id': 5, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351996', 'sent_id': 6, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS'}\n"
          ]
        }
      ],
      "source": [
        "with open('dev_data.json') as dev_data_json:\n",
        "  jdev_data = json.load(dev_data_json)\n",
        "\n",
        "print(type(jdev_data))\n",
        "print(*jdev_data[0:6], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_dic={}\n",
        "\n",
        "for i in jtrain_data:\n",
        "  if i['label'] not in train_label_dic:\n",
        "    train_label_dic[i['label']]=0\n",
        "  else :\n",
        "    train_label_dic[i['label']]+=1\n",
        "print(train_label_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5IB67v_vc0e",
        "outputId": "f309631a-782d-4254-e09c-002d6ef51f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'AFFILIATION': 41, 'OTHERS': 95, 'LOCATED': 82, 'PART_WHOLE': 23, 'PERSONAL_SOCIAL': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_label_dic={}\n",
        "\n",
        "for i in jdev_data:\n",
        "  if i['label'] not in dev_label_dic:\n",
        "    dev_label_dic[i['label']]=0\n",
        "  else :\n",
        "    dev_label_dic[i['label']]+=1\n",
        "print(dev_label_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoPacrlw5huP",
        "outputId": "ac9257bf-eaaa-4a92-d305-82e480c28738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'OTHERS': 25, 'AFFILIATION': 5, 'PART_WHOLE': 1, 'PERSONAL_SOCIAL': 5, 'LOCATED': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import namedtuple\n",
        "\n",
        "data_train = train_label_dic\n",
        "train_data = json.dumps(data_train)\n",
        "\n",
        "data_dev = dev_label_dic\n",
        "dev_data = json.dumps(data_dev)\n",
        "train = json.loads(train_data, object_hook=lambda d: namedtuple('X', d.keys())(*d.values()))\n",
        "dev = json.loads(dev_data, object_hook=lambda d: namedtuple('X', d.keys())(*d.values()))\n",
        "print(train.AFFILIATION)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPYAMFprzOBD",
        "outputId": "41049b38-0531-4f29-b6b5-04ae45462e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['AFFILIATION','OTHERS','LOCATED',\n",
        "         'PART_WHOLE', 'PERSONAL_SOCIAL']\n",
        "\n",
        "values = [train.AFFILIATION, train.OTHERS, train.LOCATED, train.PART_WHOLE, train.PERSONAL_SOCIAL]\n",
        "\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(111)\n",
        "yvals = range(len(names))\n",
        "ax.barh(yvals, values, align='center', alpha=0.4)\n",
        "plt.yticks(yvals,names)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "-0vJIEWvy8Wl",
        "outputId": "084a144a-b98d-4bfd-bd9e-56a56352913e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['AFFILIATION','OTHERS','LOCATED',\n",
        "         'PART_WHOLE', 'PERSONAL_SOCIAL']\n",
        "\n",
        "values = [dev.AFFILIATION, dev.OTHERS, dev.LOCATED, dev.PART_WHOLE, dev.PERSONAL_SOCIAL]\n",
        "\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(111)\n",
        "yvals = range(len(names))\n",
        "ax.barh(yvals, values, align='center', alpha=0.4)\n",
        "plt.yticks(yvals,names)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "PG8NQj7W6EOT",
        "outputId": "1c930537-f159-4816-8a21-80432144b3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAEYCAYAAABBfQDEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAX6ElEQVR4nO3de7SddX3n8fcHQ5SbhQhFR4nHcFEEISVpYx1UqiB4K+IFSGgVbBe6Rp2KI1WsLlkuWp16H2uZoUUDLi5qlau22gusAUXkhAkEolwiyGWo1mZUglFY8Tt/7OfUH9tzknMh2WfnvF9rPes8+/dcft99Hh7W5/zy289OVSFJkiSpZ4dBFyBJkiTNJgZkSZIkqWFAliRJkhoGZEmSJKlhQJYkSZIa8wZdgKZmzz33rJGRkUGXIUmSNPRWrVr1o6raq7/dgDxkRkZGGB0dHXQZkiRJQy/J98drd4qFJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNv2p6yKx/6GEuvP6eQZehGVqxbOGgS5AkSRNwBFmSJElqGJAlSZKkhgFZkiRJahiQJUmSpIYBWZIkSWoYkCVJkqSGAVmSJElqGJAlSZKkhgFZkiRJahiQJUmSpIYBWZIkSWoYkCVJkqSGAVmSJElqGJAlSZKkhgFZkiRJamwxICfZlGR1kluSfDHJzn3tY8u7u/ark9yW5KYkNyRZ3JzrjUnWJLm5O9+xXXuSvDfJHUluT3JVkoOa4+5O8qXm9WuTrOyr89Ik3+prOzPJOyfzi0jyZ0lu7WpbnWRZ1z4/ySeS3NnVd1mSpzXHPTnJxUnWJVmV5KtJDkgykuSWvj4+keT+JDs0bScn+avJ1ChJkqStb94k9tlYVYsBklwAvBn4WNs+jpOqajTJKcCHgaO6UPlnwGFV9ZMkuwJ7dfu/BXgecGhV/SzJS4DLkxxUVT/v9lmS5NlVtba/syS7A0uADUkWVdX3JvXuf3X87wKv6Gr7RZI9gfnd5r8AdgOeWVWbuvf05bEADVwCnFdVJ3bnOhTYG7i3r48dgOO69hcCV02lRkmSJG0bU51icQ2w3xT2vw54arf+m8CDwAaAqtpQVXd1294FvLWqftZt+zrwTeCk5lwfpRewx/Nq4ArgYuDEKdQ35inAj6rqF13/P6qq/9uNlp8CnFZVm7ptnwV+AbwI+D3gkar6n2Mnqqqbquqacfo4ArgVOBtYPo0aJUmStA1MOiAnmQe8FFjTNe3UN8XihHEOOwa4tFu/CfgBcFeSzyZ5ZXfeJwK7jDPqOwoc1Lz+AnBYkvEC+nLgom6ZTvj8OrBPN73jr5O8sGvfD7inqn46QW0HA6sm2cdYjZcAL0+y42SLS3JqktEkow/+eP1kD5MkSdI0TGaKxU5JVnfr1wDnduubm2JxQZL5wK7AYoBuesIxwG8DLwY+nmQJvekak7GJ3nSNM4C/H2tMsjewP3BtVVWSR5IcXFW3THCeX1NVG7pank9vVPjz3ZzqGyd7js3pfhcvA95RVQ8muR44GrhykvWdA5wDsOjAQ+qxqEmSJEnjm8wI8saqWtwtb6uqhydxzEnAIuA84FNjjdXz7ar6IL2pEK/pRmcfSrKo7xxL6E1JaH0OeAGwT9N2PLAHvZHpu4ERpjGKXFWbqurqqno/8FbgNcA6YGGS3Sao7dZufUuOBnYH1nQ1Hj6dGiVJkrT1bbXHvFVVAe8DnpvkWUn+U5LDml0WA9/v1j8M/I8kOwEkOZJeiLyw75yPAB8HTmualwPHVNVIVY3QC6xTmoec5JlJ9u+vraoeohfyP5bkcd2+rwd2Bv6lWx6f5NTmXIckeX5fF8uBP25qfAa9Dy7uPJU6JUmStPXNJCD3z0H+UP8OVbWR3ofrTgd2BD6S5LvdlI0TgD/pdv0UcAO9Edbb6AXrY7vj+51LNzUkyQjwdOA/Hu/WffDvJ81TJt6b5L6xZYL3sitwXpK1SW4Gng2c2W07A/g5cHuSO4DXAcd1o+FF78kUR3aPebsV+CDwr2Mn7kLwMcBXmhofAq4FXtk1ndzW2D5GTpIkSdtWehlPw2LRgYfUWSsnNXVZs9iKZQsHXYIkSXNeklVVtbS/3W/SkyRJkhqTeYrFdiPJk4B/HmfTi6vq37d1PZIkSZp95lRA7kLwRI+mkyRJkpxiIUmSJLUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSY0591fT2YMEu81mxbOGgy5AkSdpuOYIsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsMvChky6x96mAuvv2ernNsvIJEkSXIEWZIkSXoUA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1Jh1ATnJpiSrk9yS5ItJdu7a5yX5tyQf6tv/6iS3JbkpyQ1JFif5dHeOtUk2duurk7x2nP4OTbK6eb28O2bH7vVzktzc9LW02XckyS3N68OTfDvJd7vl1GbbmUneuZn3O7a8e2a/QUmSJM3EvEEXMI6NVbUYIMkFwJuBjwFHAbcDr0tyRlVVc8xJVTWa5BTgw1V1VHf8CHDl2PkmsAZYmGS3qnoQeB7wHeC3gG93r7+5paKTPBm4EHhVVd2YZE/ga0nur6qvTOb9SpIkafBm3Qhyn2uA/br15cAngXuA351g/+uAp06lg6r6JTAKLOualgCfpheM6X5+YxKneguwsqpu7M77I+BPgRmPCCc5NcloktEHf7x+pqeTJEnSZszagJxkHvBSYE2SJwBHAlcAF9ELy+M5Brh0Gt19A3hekl2AXwJX8+iA3I4gXzA2HQL4atN+ELCq77yjXfvm7NQ3xeKE/h2q6pyqWlpVS3fbfcHk35UkSZKmbDZOsdipmRN8DXAu8PvAVVW1McmXgPcleXtVber2uyDJfGBXYDrTFb4J/Leuvxuqal2S/ZLsBexaVeuafU+qqlH41RSOafTXcoqFJEnSLDIbR5A3VtXibnlbVT1Mb8T4yCR30xulfRLwouaYk4BFwHnAp6bR57eA3wb+M71pGgD3ASc2r7dkLb3pGa0lwK3TqEeSJEkDMhsD8qMkeSLwfGBhVY1U1Qi9+b6PmmbRfWjvfcBzkzxrKn10H867FziFXwXi64C3M7n5x9Cbt3xykrEPGD4J+O/AX06lFkmSJA3WrA/IwHHAv1TVL5q2y4BXJnl8u2NVbQQ+Cpw+jX6+ATy+qu7tXl9Hb1R6i0+w6Pp+APgD4G+SfLc77jNVdUWz23uT3De2dG39c5A/1H9uSZIkbTt59NPSNNstOvCQOmvlTKc9j2/FsoVb5bySJEmzUZJVVbW0v30YRpAlSZKkbWY2PsViq0nyaXofxGt9sqo+O4h6JEmSNPvMqYBcVW8ZdA2SJEma3ZxiIUmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ15tQ36W0PFuwynxXLFg66DEmSpO2WI8iSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNfyikCGz/qGHufD6ewZdhiRpC/xSJ2l4OYIsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDW2+4CcZMM4bb+R5PwkdyZZ163/RrP9gCRfTXJHkhuTfCHJ3s32TyS5P8kOSZ6TZHW3rE9yV7f+T0lGkmxstq9O8vruHHcnWdMta5OcleQJ2+a3IkmSpIls9wF5AucC36uq/apqX+Au4G8BupD6FeDsqtq/qg4D/hrYq9u+A3AccC/wwqpaU1WLq2oxcDlwevf6yK6vdWPbu+X8po7fq6rnAL8DLAL+11Z/55IkSdqseYMuYFtLsh+wBDihaf4AcGeSfYEXAtdV1RVjG6vq6mbfI4Bbgc8Dy4GrZlpTVW1I8mbg3iQLqmr9TM8pSZKk6ZmLI8jPBlZX1aaxhm59NXAQcDCwajPHLwcuAi4BXp5kxy30t2/fFIvnj7dTVf2U3kj2/v3bkpyaZDTJ6IM/NjtLkiRtTXMxIE9bkvnAy4BLu0B7PXD0Fg7rn2Jxzea6GK+xqs6pqqVVtXS33RdMr3hJkiRNypybYgGsBRYn2aGqfgn/Ma94cbdtL3rTLMZzNLA7sCYJwM7ARuDKmRaVZDdgBLh9pueSJEnS9M25EeSquhP4P8B7m+b3Ajd22y4Enpfk5WMbk7wgycH0plf8cVWNVNUI8AzgqCQ7z6SmJLvS+yDgpVX1/2ZyLkmSJM3MXAjIOye5r1neAfwRcED3iLd1wAFdG1W1EXgF8LbuMW9rgf8CPAgcQ+8JF3T7PgRcC7xyM/33z0H+r822q5LcAnwbuAd402P2riVJkjQt2/0Ui6qa6I+AP9jMMd+lF4b7/doE4Kp6dbN+ct+2u4GdJuhjZKL+JUmSNDhzYQRZkiRJmjQDsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSY15gy5AU7Ngl/msWLZw0GVIkiRttxxBliRJkhoGZEmSJKlhQJYkSZIaBmRJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhoGZEmSJKnhF4UMmfUPPcyF198z6DIkSZIeU7Ppi9AcQZYkSZIaBmRJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhoGZEmSJKlhQJYkSZIaBmRJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhoGZEmSJKlhQJYkSZIaBmRJkiSpYUCWJEmSGnM2ICd5WpLLktyRZF2STyY5OsnqbtmQ5LZu/fwkRyS5su8cK5O8tlu/utl/dZK/69rPTHJ/17Y2yfLm+Ocmub7b9p0kZ27TX4IkSZJ+zbxBFzAISQJ8GTi7qo5N8jjgHODIqlrc7XM18M6qGu1eHzGJU580tn+fj1fVR5LsD6xK8ndV9QhwHnB8Vd3U1fDMGb85SZIkzchcHUF+EfDzqvosQFVtAk4D3phk563VaVXdAfwM2KNr+k3ggbEaqmrt1upbkiRJkzNXA/JBwKq2oap+CtwD7LeZ457fTKFYDfx+3/YLmu0f7j84yWHAHVX1w67p48BtSS5J8qYkTxiv0ySnJhlNMvrgj9dP8i1KkiRpOubkFIsZuKaqXjH2IsnKvu0TTbE4LckpwAHAK8caq+oDSS4AXgKsAJYDR/QfXFXn0JsCwqIDD6kZvgdJkiRtxlwdQV4LLGkbkjwRWAjcuRX6+3hVHQS8Bji3HSmuqnVVdTbwYuDQJE/aCv1LkiRpkuZqQP5nYOckrwfoPiD3UWBlVf1sa3VaVZcDo8Abun5f3n1gEGB/YBPw463VvyRJkrZsTgbkqirgOOB1Se4Abgd+Drxnhqdu5yD/0wT7fAB4R5IdgD+kNwd5NfA5elM0Ns2wBkmSJM1AellRw2LRgYfUWSuv3PKOkiRJQ2TFsoXbvM8kq6pqaX/7nBxBliRJkiZiQJYkSZIaBmRJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhoGZEmSJKlhQJYkSZIaBmRJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhoGZEmSJKkxb9AFaGoW7DKfFcsWDroMSZKk7ZYjyJIkSVLDgCxJkiQ1DMiSJElSw4AsSZIkNQzIkiRJUsOALEmSJDUMyJIkSVLDgCxJkiQ1DMiSJElSw2/SGzLrH3qYC6+/Z9BlaIb8NkRJkmYvR5AlSZKkhgFZkiRJahiQJUmSpIYBWZIkSWoYkCVJkqSGAVmSJElqGJAlSZKkhgFZkiRJahiQJUmSpIYBWZIkSWoYkCVJkqSGAVmSJElqGJAlSZKkhgFZkiRJagxdQE7yqiSV5Fnd65EkG5Osbpb5SU5O8m9N2/nd/iuTvLZbvzrJ0r7zH5Hkyr62S5N8q1s/ujnnhiS3jZ2//9iu1puTfCfJmiSvaratTHJ/ksd3r/dMcvdW+rVJkiRpkuYNuoBpWA5c2/18f9e2rqoWtzslAfh8Vb11Jp0l2R1YAmxIsqiqvgZ8rdt2NfDOqhrtXh/RHHco8BHgqKq6K8kzgH9M8r2qurnbbRPwRuDsmdQoSZKkx85QjSAn2RU4HPgj4MRt1O2rgSuAi6fY5zuBv6iquwC6nx8ETm/2+QRwWpJh/ENFkiRpuzRUARk4FviHqrod+PckS7r2fZtpD59u9j+haT9lmn0uBy7qluVTOO4gYFVf22jXPuYeeqPhfzjN2iRJkvQYG7aRy+XAJ7v1i7vXf8U4Uyw6M5pikWRvYH/g2qqqJI8kObiqbpnuOcfxQeAy4CubqeNU4FSAPZ/81Mewa0mSJPUbmhHkJAuAFwF/232Y7XTgeCBbsdvjgT2Au7o+R5j8KPJaenOXW0uAW9uGqroDWN31Na6qOqeqllbV0t12XzDJ7iVJkjQdQxOQgdcCn6uqp1fVSFXtA9wF7LMV+1wOHNP1N0Iv4E52HvJHgDOSjEDvaRvAe4CPjrPvn9ObsyxJkqQBG6aAvBy4pK/tS8AZMzzvV5Lc1y1fHGvsAu3TgW+NtXUftPtJkmVbOmlVrQbeBVyR5Lv0Puj3p117/763AjfO8H1IkiTpMZCqGnQNmoJFBx5SZ628css7alZbsWzhoEuQJGnOS7Kqqpb2tw/TCLIkSZK01RmQJUmSpIYBWZIkSWoYkCVJkqSGAVmSJElqGJAlSZKkhgFZkiRJahiQJUmSpIYBWZIkSWoYkCVJkqSGAVmSJElqGJAlSZKkhgFZkiRJaswbdAGamgW7zGfFsoWDLkOSJGm75QiyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUMCBLkiRJDQOyJEmS1DAgS5IkSQ0DsiRJktQwIEuSJEkNA7IkSZLUSFUNugZNQZIHgdsGXYdmbE/gR4MuQjPmddw+eB2Hn9dw+zCI6/j0qtqrv3HeNi5CM3dbVS0ddBGamSSjXsfh53XcPngdh5/XcPswm66jUywkSZKkhgFZkiRJahiQh885gy5Ajwmv4/bB67h98DoOP6/h9mHWXEc/pCdJkiQ1HEGWJEmSGgZkSZIkqWFAHiJJjklyW5I7k7x70PVoepLcnWRNktVJRgddjyYnyWeS/DDJLU3bgiT/mOSO7uceg6xRmzfBNTwzyf3d/bg6ycsGWaO2LMk+Sa5KsjbJrUn+pGv3fhwim7mOs+KedA7ykEjyOOB24CjgPuAGYHlVrR1oYZqyJHcDS6vKh9oPkSQvADYA51fVwV3bXwLrq+pD3R+te1TVuwZZpyY2wTU8E9hQVR8ZZG2avCRPAZ5SVTcm2Q1YBbwKOBnvx6Gxmet4PLPgnnQEeXj8DnBnVX2vqh4GLgaOHXBN0pxRVf8bWN/XfCxwXrd+Hr3/uWuWmuAaashU1QNVdWO3/iDwHeCpeD8Olc1cx1nBgDw8ngrc27y+j1n0H5KmpICvJ1mV5NRBF6MZ2buqHujW/xXYe5DFaNremuTmbgqG/yw/RJKMAL8FXI/349Dqu44wC+5JA7K07R1eVYcBLwXe0v2zr4Zc9earOWdt+JwN7AssBh4APjrYcjRZSXYFvgS8vap+2m7zfhwe41zHWXFPGpCHx/3APs3rp3VtGjJVdX/384fAJfSmz2g4/aCbRzc2n+6HA65HU1RVP6iqTVX1S+Bv8H4cCkl2pBeqLqiqL3fN3o9DZrzrOFvuSQPy8LgB2D/JM5LMB04ELh9wTZqiJLt0H0YgyS7AS4BbNn+UZrHLgTd0628ALhtgLZqGsUDVOQ7vx1kvSYBzge9U1ceaTd6PQ2Si6zhb7kmfYjFEukedfAJ4HPCZqvrzAZekKUqyiN6oMcA84EKv43BIchFwBLAn8APg/cClwBeAhcD3geOryg+BzVITXMMj6P1TbgF3A29q5rFqFkpyOHANsAb4Zdf8HnrzV70fh8RmruNyZsE9aUCWJEmSGk6xkCRJkhoGZEmSJKlhQJYkSZIaBmRJkiSpYUCWJEmSGgZkSZIkqWFAliRJkhr/H2GclLfaTCVhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7U1qDne3hL1"
      },
      "outputs": [],
      "source": [
        "flags = {\n",
        "    'pb_emb_layer_lst': [10,11,12,13],             # danh sách các layer mà ta sẽ lấy embedding. từ 1 -> 13 cho phobert_base, 1 -> 25 cho phobert_large. \n",
        "                                                   # layer số 1 là initial embeddin\n",
        "    'phobert_num_epochs': 3,    # num epoch of fintune phobert. after this epoch, we will freeze phobert layer. 0 mean no finetune.\n",
        "    \n",
        "    # implemented\n",
        "    'total_epochs': 100,       #\n",
        "    'batch_size': 16,        # 8, 16, 64\n",
        "\t\n",
        "    'dropout1_rate': 0.6,\n",
        "    'out_linear1': 1024,\n",
        "    'dropout2_rate': 0.2,\n",
        "\n",
        "    'clip_grad_norm_rate': 5.0,\n",
        "\t\n",
        "\n",
        "    'linear_lr': 0.00001,\n",
        "    'linear_lr_schedule_epoch': 6,\n",
        "    'linear_lr_schedule_rate': 0.9,\n",
        "    'linear_weight_decay': 0.15,\n",
        "\t\n",
        "    #\n",
        "    'linear_betas': (0.9, 0.999),\n",
        "    'linear_eps': 1e-6,\n",
        "\t\n",
        "    'seed': 5,\n",
        "    'log_batch': 30,\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AU_ZnA9O341k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer, RobertaForSequenceClassification, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "087c9f75c19e4859ab007e3cd760716b",
            "ab8b4c04a9894b2aa1d2f5169d2e7831",
            "6c5b993859a3447bab3a1ef55df5f65f",
            "36b78dd5800341c691465272cd2852e7",
            "69c4956c1f274184bd96a6a141cc1fce",
            "de3e27c8b75341f1a9f24f302a59f0ab",
            "4b58d3d2d0ca41858aa22ee00d8cc87d",
            "565a78cf18344b5481621920e15aa1f0",
            "1afe3e490abc461b80301ca86fb83f8e",
            "9fb0165c881f48379879393b2f87b03a",
            "93e9238fc87142dc8db18815b5584576",
            "428a3d910dd04e128c4712dbe6e0e1ab",
            "0529d09c36f04b07a5e10a24981dcc0a",
            "aa039e38fac64b589c26cd5bd2d710ac",
            "ca7956fa69bb4e329966fbd159a0b13a",
            "aaace6a4fb4749e28a9435cc81350a5e",
            "04711edee7194914aef9b741c6cb4517",
            "a49f3ac536184819bb0139a978e3fbc6",
            "cb1d95abb9a84189b1f2f1eb9a4e4076",
            "ac6de59ae71b4b9a8561abcff7d8b8f4",
            "c8365eb5207c40bd99bb5080ee14c6f8",
            "fdb1e6e5584e48469e91d67515e76c06",
            "2b385132100a4e548f19ab6ff939518c",
            "b32525bfe39344ab9fb664173740bbad",
            "90b8078798cb4e369ef23b17ed5c60a2",
            "ad8da13a006d4fd1b94fb929c9639779",
            "64d068395b1b4b7cb84c71bb1b1bd9b5",
            "e8e9e3d26c824308ab9e17542cd54fe0",
            "6367adf606ca44c29960ca34eb747f3c",
            "94c7c9aea515475ea83ac07f7f0174f4",
            "96acf949f1244f098bea61647741d072",
            "6abb078571254917adbb4874ba08baa5",
            "001b4f1f0ea54f8ba642f39722a2aedc"
          ]
        },
        "id": "6fUxLjns4FP6",
        "outputId": "7ab6737a-9230-4012-a1fa-6546b80aeafc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "087c9f75c19e4859ab007e3cd760716b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "428a3d910dd04e128c4712dbe6e0e1ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b385132100a4e548f19ab6ff939518c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "pb_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cmHMz-y5zpZ"
      },
      "outputs": [],
      "source": [
        "def my_word_tokenize(word_tokenize_lst, tokens_non_space_pos_lst, split_token_index, split_pos, sentence):\n",
        "\n",
        "    '''\n",
        "    word_tokenize_lst: word_tokenize_lst cần được sửa\n",
        "    tokens_non_space_pos_lst: vị trí pos indice của mọi token trong word_tokenize_lst đối với câu không có space\n",
        "    split_token_index: index của token cần được tách trong word_tokenize_lst\n",
        "    sentence: sentence gốc có space\n",
        "    split_pos: vị trí (NON SPACE) đối với câu (tại vị trí này ta sẽ tách token cần tách thành 2 phần, từ đầu token tới vị trí này,\n",
        "    và từ vị trí này đến hết token)\n",
        "    vị trí này sẽ nằm giữa đầu vs cuối của token)\n",
        "    ..... vitri_dau_token  vitri_tach_token   vitri_cuoi_token ...\n",
        "    '''\n",
        "\n",
        "    new_word_tokenize_lst = []\n",
        "    new_tokens_non_space_pos_lst = []\n",
        "\n",
        "    for itk, tk in enumerate(word_tokenize_lst):\n",
        "\n",
        "        if itk != split_token_index:\n",
        "            sent_non_space = ''.join(sentence.split())   # remove all space from original sentence\n",
        "            token_non_space = ''.join(tk.split())  # remove all space from current tk\n",
        "            token_non_space_pos = tokens_non_space_pos_lst[itk]\n",
        "                \n",
        "            new_word_tokenize_lst.append(tk)  # tk with space\n",
        "            new_tokens_non_space_pos_lst.append(copy.deepcopy(tokens_non_space_pos_lst[itk]))  # non space pos\n",
        "\n",
        "        \n",
        "        \n",
        "        else:   # token cần tách\n",
        "            token_space = copy.deepcopy(word_tokenize_lst[split_token_index])  \n",
        "\n",
        "            sent_non_space = ''.join(sentence.split()) \n",
        "            token_non_space = ''.join(token_space.split())  \n",
        "\n",
        "            token_non_space_pos = tokens_non_space_pos_lst[split_token_index] \n",
        "\n",
        "            token_head_non_space = sent_non_space[token_non_space_pos[0]:split_pos]   \n",
        "            token_tail_non_space = sent_non_space[split_pos:token_non_space_pos[1]] \n",
        "\n",
        "\n",
        "            subtoken_lst = token_space.split()\n",
        "\n",
        "            \n",
        "            num_space_in_token_space = 0\n",
        "            for ctk in token_space:\n",
        "                if ctk.isspace():\n",
        "                    num_space_in_token_space += 1\n",
        "      \n",
        "            sub_token_head_lst = []\n",
        "\n",
        "            for subtoken in subtoken_lst:          \n",
        "                sub_token_head_lst.append(subtoken)  \n",
        "                if ''.join(sub_token_head_lst) == token_head_non_space:   \n",
        "                    break\n",
        "                \n",
        "            sub_token_tail_lst = subtoken_lst[len(sub_token_head_lst):]   # [C, D]\n",
        "\n",
        "            new_word_tokenize_lst.append(' '.join(sub_token_head_lst))\n",
        "\n",
        "            token_head_non_space_pos_start = token_non_space_pos[0]\n",
        "            token_head_non_space_pos_end = token_head_non_space_pos_start + sum([len(tmp) for tmp in sub_token_head_lst])\n",
        "\n",
        "       \n",
        "            new_tokens_non_space_pos_lst.append([token_head_non_space_pos_start, token_head_non_space_pos_end])\n",
        "            new_word_tokenize_lst.append(' '.join(sub_token_tail_lst))\n",
        "\n",
        "            token_tail_non_space_pos_start = split_pos\n",
        "            token_tail_non_space_pos_end = token_tail_non_space_pos_start + sum([len(tmp) for tmp in sub_token_tail_lst])\n",
        "\n",
        "          \n",
        "            new_tokens_non_space_pos_lst.append([token_tail_non_space_pos_start, token_tail_non_space_pos_end])\n",
        "                \n",
        "\n",
        "    return new_word_tokenize_lst, new_tokens_non_space_pos_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6z-ehbm52Q-"
      },
      "outputs": [],
      "source": [
        "def get_entity_index_in_underthesea_word_tokenize(sentence, word_tokenize_lst, entity):\n",
        "    \n",
        "    entity_text = entity['text']\n",
        "    entity_pos = entity['pos']\n",
        "\n",
        "    # đếm khoảng trắng từ đầu câu đến entity start_pos\n",
        "    count_to_estart = 0\n",
        "    for c in sentence[:entity_pos[0]]:\n",
        "        if c.isspace():\n",
        "            count_to_estart += 1\n",
        "    new_estart_pos = entity_pos[0] - count_to_estart\n",
        "\n",
        "    # đếm khoảng trắng từ đầu câu đến entity end_pos\n",
        "    count_to_eend = 0\n",
        "    for c in sentence[:entity_pos[1]]:\n",
        "        if c.isspace():\n",
        "            count_to_eend += 1\n",
        "    new_eend_pos = entity_pos[1] - count_to_eend\n",
        "\n",
        "\n",
        "    pre_tkend_pos = 0\n",
        "\n",
        "    found_start = False\n",
        "    found_end = False\n",
        "\n",
        "    start_index = None\n",
        "    end_index = None\n",
        "    \n",
        "    \n",
        "    sent_non_space = ''.join(sentence.split()) \n",
        "    tokens_non_space_pos_lst = []  \n",
        "\n",
        "\n",
        "    for itk, tk in enumerate(word_tokenize_lst):\n",
        "        # tìm pos của từng token trong câu segment\n",
        "        tkstart_pos = pre_tkend_pos \n",
        "        tkend_pos = tkstart_pos + sum([len(tmp) for tmp in tk.split()])\n",
        "\n",
        "        token_non_space = ''.join(tk.split())\n",
        "\n",
        "        tokens_non_space_pos_lst.append([tkstart_pos, tkend_pos])\n",
        "\n",
        "        # cập nhật pre_tkend_pos\n",
        "        pre_tkend_pos = tkend_pos\n",
        "\n",
        "\n",
        "        if tkstart_pos == new_estart_pos:\n",
        "            found_start = True\n",
        "            start_index = copy.deepcopy(itk)\n",
        "\n",
        "        if tkend_pos == new_eend_pos:\n",
        "            found_end = True\n",
        "            end_index = copy.deepcopy(itk)\n",
        "\n",
        "        if (tkstart_pos < new_estart_pos) and (new_estart_pos < tkend_pos):\n",
        "            start_index = copy.deepcopy(itk)  \n",
        "\n",
        "        if (tkstart_pos < new_eend_pos) and (new_eend_pos < tkend_pos):\n",
        "            end_index = copy.deepcopy(itk) \n",
        "\n",
        "    \n",
        "    entity_eids_lst = []\n",
        "    new_word_tokenize_lst = []\n",
        "    new_tokens_non_space_pos_lst = []\n",
        "\n",
        "    if (found_start == True):\n",
        "        new_word_tokenize_lst = copy.deepcopy(word_tokenize_lst)\n",
        "        new_tokens_non_space_pos_lst = copy.deepcopy(tokens_non_space_pos_lst)\n",
        "\n",
        "    if found_start == False:\n",
        "        token_space = word_tokenize_lst[start_index]\n",
        "\n",
        "        num_space_in_token_space = 0\n",
        "        for ctk in token_space:\n",
        "            if ctk.isspace():\n",
        "                num_space_in_token_space += 1\n",
        "\n",
        "     \n",
        "        new_word_tokenize_lst, new_tokens_non_space_pos_lst = \\\n",
        "        my_word_tokenize(word_tokenize_lst, tokens_non_space_pos_lst, start_index, new_estart_pos, sentence)\n",
        "        start_index = start_index + 1  # osi + 1\n",
        "        end_index = end_index + 1\n",
        "\n",
        "\n",
        "                \n",
        "    if found_end == True:\n",
        "        entity_eids_lst = list(range(start_index, (end_index+1)))\n",
        "\n",
        "\n",
        "    if found_end == False:\n",
        "        new_word_tokenize_lst, new_tokens_non_space_pos_lst = \\\n",
        "        my_word_tokenize(copy.deepcopy(new_word_tokenize_lst), copy.deepcopy(new_tokens_non_space_pos_lst), end_index, new_eend_pos, sentence)\n",
        "\n",
        "        entity_eids_lst = list(range(start_index, (end_index+1)))\n",
        "\n",
        "\n",
        "\n",
        "    entity_text_no_space = ''.join(entity_text.split()) \n",
        "    entity_subtoken_lst = new_word_tokenize_lst[entity_eids_lst[0]:(entity_eids_lst[-1]+1)]\n",
        "\n",
        "    entity_singleword_lst = []\n",
        "    for entity_subtoken in entity_subtoken_lst:\n",
        "        entity_singleword_lst.extend(entity_subtoken.split())\n",
        "\n",
        "    entity_pos_no_space = [new_estart_pos, new_eend_pos]\n",
        "\n",
        "    return new_word_tokenize_lst, entity_eids_lst, entity_pos_no_space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBfWDUqV5-f6"
      },
      "outputs": [],
      "source": [
        "def add_word_tokenize_and_entity_index(jdata, train_or_dev):\n",
        "\n",
        "    new_jdata = []\n",
        "\n",
        "    for sentif in jdata:\n",
        "\n",
        "        word_tokenize_lst = word_tokenize(sentif['sentence'])\n",
        "\n",
        "        new_word_tokenize_lst_1, entity_1_eids_lst, entity_1_pos_no_space = \\\n",
        "        get_entity_index_in_underthesea_word_tokenize(sentif['sentence'], word_tokenize_lst, sentif['entity_1'])\n",
        "\n",
        "        new_word_tokenize_lst_2, entity_2_eids_lst, entity_2_pos_no_space = \\\n",
        "        get_entity_index_in_underthesea_word_tokenize(sentif['sentence'], copy.deepcopy(new_word_tokenize_lst_1), sentif['entity_2'])\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        new_sentif = copy.deepcopy(sentif)\n",
        "\n",
        "        new_sentif['word_tokenize_lst'] = copy.deepcopy(new_word_tokenize_lst_2)\n",
        "        new_sentif['entity_1']['pos_no_space'] = copy.deepcopy(entity_1_pos_no_space)\n",
        "        new_sentif['entity_2']['pos_no_space'] = copy.deepcopy(entity_2_pos_no_space)\n",
        "\n",
        "\n",
        "        new_jdata.append(copy.deepcopy(new_sentif))\n",
        "    return new_jdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj4nfpAZ6ItS"
      },
      "outputs": [],
      "source": [
        "def get_entity_word_piece_index(bert_tokenize_lst, entity, sentence, input_ids, train_or_dev):\n",
        "\n",
        "    entity_pos_no_space = entity['pos_no_space']\n",
        "\n",
        "    sent_non_space = ''.join(sentence.split())\n",
        "\n",
        "    found_start, found_end = None, None\n",
        "    start_index, end_index = None, None\n",
        "\n",
        "    pre_wpiend_pos = 0\n",
        "\n",
        "  \n",
        "\n",
        "    for iwpi, wpi in enumerate(bert_tokenize_lst):\n",
        "        clean_wpi = wpi.replace('_', '')\n",
        "        clean_wpi = clean_wpi.replace('@@', '')\n",
        "  \n",
        "        wpi_start_pos = copy.deepcopy(pre_wpiend_pos)\n",
        "        wpi_end_pos = wpi_start_pos + len(clean_wpi)\n",
        "\n",
        "        pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n",
        "\n",
        "        if wpi_start_pos == entity_pos_no_space[0]:\n",
        "            start_index = iwpi\n",
        "            found_start = True\n",
        "\n",
        "        if wpi_end_pos == entity_pos_no_space[1]:\n",
        "            end_index = iwpi\n",
        "            found_end = True\n",
        "            break\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "    found_entity_text = ''.join(bert_tokenize_lst[start_index:(end_index+1)])\n",
        "    found_entity_text = found_entity_text.replace('_', '')\n",
        "    found_entity_text = found_entity_text.replace('@@', '')\n",
        "    found_entity_text = found_entity_text.replace('▁', '')\n",
        "\n",
        "\n",
        "    entity_text_no_space = ''.join(entity['text'].split())\n",
        "\n",
        "    entity_wpi_ids_lst = list(range((start_index+1), (end_index+2)))\n",
        "\n",
        "\n",
        "    tmp_ent_txt = ''\n",
        "\n",
        "    for entity_wpi_id in entity_wpi_ids_lst:\n",
        "      tmp_ent_txt += pb_tokenizer.decode([input_ids[entity_wpi_id]])\n",
        "    \n",
        "    tmp_ent_txt = tmp_ent_txt.replace(' ', '')\n",
        "    tmp_ent_txt = tmp_ent_txt.replace('_', '')\n",
        "    tmp_ent_txt = tmp_ent_txt.replace('@@', '')\n",
        "    \n",
        "    return entity_wpi_ids_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtXZa4ez6KtT"
      },
      "outputs": [],
      "source": [
        "def encode_label(sentence_label):\n",
        "    label = -1\n",
        "    if sentence_label == \"LOCATED\":\n",
        "        label = 0\n",
        "    elif sentence_label == \"PART_WHOLE\":\n",
        "        label = 1\n",
        "    elif sentence_label == \"PERSONAL_SOCIAL\":\n",
        "        label = 2\n",
        "    elif sentence_label == \"AFFILIATION\":\n",
        "        label = 3\n",
        "    elif sentence_label == \"OTHERS\":\n",
        "        label = 4\n",
        "    if label ==-1:\n",
        "      print(sentence_label)\n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKgn7Ky86Nkj"
      },
      "outputs": [],
      "source": [
        "jtrain_data = add_word_tokenize_and_entity_index(jtrain_data, 'train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deGrNcvY8XH2",
        "outputId": "31b81e71-3cba-4484-d818-0456a9a2db6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'doc_id': '23351113', 'sent_id': 1, 'sentence': 'Ảnh minh họa Thứ trưởng Bộ GD&ĐT Nguyễn Thị Nghĩa đã có ý kiến về vấn đề này.', 'spos': [311, 388], 'entity_1': {'text': 'Bộ GD&ĐT', 'pos': [24, 32], 'pos_no_space': [19, 26]}, 'entity_2': {'text': 'Nguyễn Thị Nghĩa', 'pos': [33, 49], 'pos_no_space': [26, 40]}, 'label': 'AFFILIATION', 'word_tokenize_lst': ['Ảnh', 'minh họa', 'Thứ trưởng', 'Bộ', 'GD&ĐT', 'Nguyễn Thị Nghĩa', 'đã', 'có', 'ý kiến', 'về', 'vấn đề', 'này', '.']}\n"
          ]
        }
      ],
      "source": [
        "print(jtrain_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MJD6i8H8Esr"
      },
      "outputs": [],
      "source": [
        "train_pb_input_ids = []\n",
        "train_pb_attention_masks = []\n",
        "train_pb_entity_1_eids = []\n",
        "train_pb_entity_2_eids = []\n",
        "train_labels = []\n",
        "\n",
        "# Do entity_eids của các entity trong các câu không cùng chiều dài nên ta cần chuyển về cùng chiều dài thì mới biến thành tensor được\n",
        "# để chuyển về cùng chiều dài ta sẽ pad các eids ngắn hơn bằng -2.\n",
        "# vì eids phải >= 1 nên để số < 0 sẽ không sợ nhầm và ta chỉ thêm vào bên phải. \n",
        "# >= 1 vì lúc tìm eids đã tính <s> nên đã +1 sẵn nên min = 1\n",
        "# giả sử 1 entity_eids chỉ có chiều dài max là 30\n",
        "pad_ent_eid = -2\n",
        "max_len_ent_eid = 30\n",
        "\n",
        "\n",
        "jtrain_data_use = copy.deepcopy(jtrain_data)\n",
        "\n",
        "for isentif, sentif in enumerate(jtrain_data_use):\n",
        "         \n",
        "    pb_input_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n",
        "\n",
        "    pb_encode_dict = pb_tokenizer(pb_input_sent, add_special_tokens=True, padding='max_length', max_length=192)\n",
        "\n",
        "    pb_tokenize_lst = pb_tokenizer.tokenize(pb_input_sent)\n",
        "   \n",
        "    pb_entity_1_eids = get_entity_word_piece_index(pb_tokenize_lst, sentif['entity_1'], sentif['sentence'], pb_encode_dict['input_ids'], 'train')\n",
        "    pb_entity_2_eids = get_entity_word_piece_index(pb_tokenize_lst, sentif['entity_2'], sentif['sentence'], pb_encode_dict['input_ids'], 'train')\n",
        "\n",
        "    # pad\n",
        "   \n",
        "    pb_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_entity_1_eids))\n",
        "    pb_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_entity_2_eids))\n",
        "        \n",
        "        \n",
        "    train_pb_input_ids.append(copy.deepcopy(pb_encode_dict['input_ids']))\n",
        "    train_pb_attention_masks.append(copy.deepcopy(pb_encode_dict['attention_mask']))\n",
        "    train_pb_entity_1_eids.append(copy.deepcopy(pb_entity_1_eids))\n",
        "    train_pb_entity_2_eids.append(copy.deepcopy(pb_entity_2_eids))\n",
        "   \n",
        "    train_labels.append(copy.deepcopy(encode_label(sentif['label'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDhEM6_f89iR"
      },
      "outputs": [],
      "source": [
        "# convert to tensor\n",
        "train_pb_input_ids = torch.tensor(train_pb_input_ids)\n",
        "train_pb_attention_masks = torch.tensor(train_pb_attention_masks)\n",
        "train_pb_entity_1_eids = torch.tensor(train_pb_entity_1_eids)\n",
        "train_pb_entity_2_eids = torch.tensor(train_pb_entity_2_eids)\n",
        "train_labels = torch.tensor(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBySd2xx9XrN"
      },
      "outputs": [],
      "source": [
        "#dev\n",
        "jdev_data = add_word_tokenize_and_entity_index(jdev_data, 'dev')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLPKmE6C-ISn",
        "outputId": "29c10d6b-8f03-46c7-d81f-9dfe445071e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'doc_id': '23351996', 'sent_id': 1, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12], 'pos_no_space': [0, 10]}, 'entity_2': {'text': 'Mông Cổ', 'pos': [36, 43], 'pos_no_space': [28, 34]}, 'label': 'OTHERS', 'word_tokenize_lst': ['U16', 'Việt Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông Cổ', 'Không', 'nằm', 'ngoài', 'dự đoán', ',', 'U16', 'Việt Nam', 'đã', 'có', 'chiến thắng', 'dễ dàng', 'trước', 'U16', 'Mông Cổ', '.']}\n"
          ]
        }
      ],
      "source": [
        "print(jdev_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G87ssmB1-XNp"
      },
      "outputs": [],
      "source": [
        "dev_pb_input_ids = []\n",
        "dev_pb_attention_masks = []\n",
        "dev_pb_entity_1_eids = []\n",
        "dev_pb_entity_2_eids = []\n",
        "dev_labels = []\n",
        "\n",
        "pad_ent_eid = -2\n",
        "max_len_ent_eid = 30\n",
        "\n",
        "\n",
        "\n",
        "jdev_data_use = copy.deepcopy(jdev_data)\n",
        "\n",
        "\n",
        "for isentif, sentif in enumerate(jdev_data_use):\n",
        "\n",
        "\n",
        "  pb_input_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n",
        "\n",
        "  pb_encode_dict = pb_tokenizer(pb_input_sent, add_special_tokens=True, padding='max_length', max_length=192)\n",
        "  pb_tokenize_lst = pb_tokenizer.tokenize(pb_input_sent)\n",
        "\n",
        "  pb_entity_1_eids = get_entity_word_piece_index(pb_tokenize_lst, sentif['entity_1'], sentif['sentence'], pb_encode_dict['input_ids'], 'dev')\n",
        "  pb_entity_2_eids = get_entity_word_piece_index(pb_tokenize_lst, sentif['entity_2'], sentif['sentence'], pb_encode_dict['input_ids'], 'dev')\n",
        "\n",
        "  # pad\n",
        "  \n",
        "  pb_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_entity_1_eids))\n",
        "  pb_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_entity_2_eids))\n",
        "  \n",
        "  dev_pb_input_ids.append(copy.deepcopy(pb_encode_dict['input_ids']))\n",
        "  dev_pb_attention_masks.append(copy.deepcopy(pb_encode_dict['attention_mask']))\n",
        "  dev_pb_entity_1_eids.append(copy.deepcopy(pb_entity_1_eids))\n",
        "  dev_pb_entity_2_eids.append(copy.deepcopy(pb_entity_2_eids))\n",
        "  dev_labels.append(copy.deepcopy(encode_label(sentif['label'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkS_KqWA-zzu"
      },
      "outputs": [],
      "source": [
        "# convert to tensor\n",
        "\n",
        "dev_pb_input_ids = torch.tensor(dev_pb_input_ids)\n",
        "dev_pb_attention_masks = torch.tensor(dev_pb_attention_masks)\n",
        "dev_pb_entity_1_eids = torch.tensor(dev_pb_entity_1_eids)\n",
        "dev_pb_entity_2_eids = torch.tensor(dev_pb_entity_2_eids)\n",
        "dev_labels = torch.tensor(dev_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSxbwBvH_A9B"
      },
      "outputs": [],
      "source": [
        "class BERTModel(nn.Module):\n",
        "    def __init__(self, emb_layer_lst):\n",
        "        super().__init__()\n",
        "        self.bert_model = AutoModel.from_pretrained(\"vinai/phobert-base\", output_hidden_states=True)\n",
        "          \n",
        "        self.emb_layer_lst = emb_layer_lst\n",
        "        self.sent_emb_len, self.wpi_emb_len = self.calculate_len_embedding()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, b_input_ids, b_attention_mask, b_entity_1_eids, b_entity_2_eids):\n",
        "        outputs = self.bert_model(b_input_ids, b_attention_mask)\n",
        "\n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "        b_sent_final_embedding = self.get_sent_final_vector(hidden_states, b_entity_1_eids, b_entity_2_eids)\n",
        "\n",
        "        return b_sent_final_embedding\n",
        "\n",
        "    def get_sent_final_vector(self, hidden_states, b_entity_1_eids, b_entity_2_eids):\n",
        "      \n",
        "            \n",
        "        sent_final_embedding_lst = []\n",
        "\n",
        "        for isent in range(len(b_entity_1_eids)):   # từng câu 1 trong batch\n",
        "\n",
        "            \n",
        "            entity_1_final_vector = self.get_entity_embedding_vector(hidden_states, b_entity_1_eids[isent], isent)\n",
        "            entity_2_final_vector = self.get_entity_embedding_vector(hidden_states, b_entity_2_eids[isent], isent)\n",
        "\n",
        "            entity_sum_vector = torch.add(entity_1_final_vector, entity_2_final_vector)\n",
        "            entity_mul_vector = torch.mul(entity_1_final_vector, entity_2_final_vector)\n",
        "            entity_abs_sub_vector = torch.abs(torch.sub(entity_1_final_vector, entity_2_final_vector))\n",
        "\n",
        "            sent_final_vector = torch.cat((entity_1_final_vector, entity_2_final_vector, entity_mul_vector, entity_sum_vector, entity_abs_sub_vector))\n",
        "\n",
        "            sent_final_embedding_lst.append(sent_final_vector)\n",
        "\n",
        "\n",
        "        \n",
        "        sent_final_embedding_lst = torch.stack(sent_final_embedding_lst)  \n",
        "        return sent_final_embedding_lst\n",
        "                \n",
        "\n",
        "    def get_entity_embedding_vector(self, hidden_states, entity_eids, isent):\n",
        "        entity_wpi_embedding_lst = []\n",
        "        for ient_eid, entity_eid in enumerate(entity_eids):               \n",
        "\n",
        "            if entity_eid < 0: \n",
        "                break\n",
        "\n",
        "            wpi_final_vector = None\n",
        "            wpi_embedding_lst = []\n",
        "            # thu thập mọi vector trong các layer muốn lấy của 1 word piece\n",
        "            for emb_layer in self.emb_layer_lst:          # từng layer mà ta muốn lấy embedding\n",
        "                wpi_embedding_lst.append(hidden_states[emb_layer-1][isent][entity_eid])\n",
        "                \n",
        "            # xử lý embedding thuộc các layer khác nhau của 1 word piece -sum\n",
        "            wpi_embedding_lst = torch.stack(wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n",
        "            wpi_final_vector = torch.sum(wpi_embedding_lst, dim=0)   \n",
        "\n",
        "          \n",
        "            entity_wpi_embedding_lst.append(wpi_final_vector)\n",
        "            \n",
        "\n",
        "      \n",
        "        # xử lý embedding của mọi word piece trong 1 entity - average_pooling\n",
        "        entity_wpi_embedding_lst = torch.stack(entity_wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n",
        "        entity_final_vector = torch.mean(entity_wpi_embedding_lst, dim=0)\n",
        "      \n",
        "        return entity_final_vector\n",
        "\n",
        "\n",
        "\n",
        "    #  tính len của vector đại diện cho câu\n",
        "    def calculate_len_embedding(self):\n",
        "        wpi_emb_len = 768\n",
        "        sent_emb_len = wpi_emb_len * 5\n",
        "        \n",
        "        return sent_emb_len, wpi_emb_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EtPueZ-_Sfh"
      },
      "outputs": [],
      "source": [
        "class REClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, flags):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.pb_model = BERTModel(flags['pb_emb_layer_lst'])\n",
        "        pb_sent_emb_len = self.calculate_len_sent_embedding(flags['pb_emb_layer_lst'])\n",
        "\n",
        "        self.final_sent_emb_len = pb_sent_emb_len\n",
        "\n",
        "\n",
        "        self.flags = flags\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p=flags['dropout1_rate'])\n",
        "        self.linear1 = nn.Linear(self.final_sent_emb_len, flags['out_linear1'])\n",
        "        self.dropout2 = nn.Dropout(p=flags['dropout2_rate'])\n",
        "        self.linear2 = nn.Linear(flags['out_linear1'], 5)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids):\n",
        "        bert_sent_final_embedding = self.pb_model(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids)\n",
        "\n",
        "        x = self.dropout1(bert_sent_final_embedding)\n",
        "        x = self.linear1(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    #  tính len của vector đại diện cho câu\n",
        "    def calculate_len_sent_embedding(self, emb_layer_lst):\n",
        "        wpi_emb_len = 768\n",
        "        sent_emb_len = wpi_emb_len * 5\n",
        "\n",
        "\n",
        "        return sent_emb_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_pN4KT8_jcB"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(train_pb_input_ids, train_pb_attention_masks, train_pb_entity_1_eids, train_pb_entity_2_eids, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GXyOzX6_mjD"
      },
      "outputs": [],
      "source": [
        "dev_dataset = TensorDataset(dev_pb_input_ids, dev_pb_attention_masks, dev_pb_entity_1_eids, dev_pb_entity_2_eids, dev_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzmoQ7QQ_uc_"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8f3090JJ8GO"
      },
      "outputs": [],
      "source": [
        "data=np.concatenate((train_pb_attention_masks.numpy(), train_pb_attention_masks.numpy(), train_pb_entity_1_eids.numpy(),train_pb_entity_2_eids.numpy()), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gkjh1Is1VPIq"
      },
      "outputs": [],
      "source": [
        "dev=np.concatenate((dev_pb_input_ids.numpy(), dev_pb_attention_masks.numpy(), dev_pb_entity_1_eids.numpy(),dev_pb_entity_2_eids.numpy()), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmtdjrq_Idww"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import linear_model\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zsfu_89LIYmm"
      },
      "outputs": [],
      "source": [
        "svc = LinearSVC()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL3jcLZmIgFX",
        "outputId": "37e6c276-6292-4cd6-cd93-027384baa8ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "svc.fit(data, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14S-XHA7VWXA"
      },
      "outputs": [],
      "source": [
        "svc_prediction=svc.predict(dev)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svc_Accurancy= accuracy_score(dev_labels , svc_prediction)\n",
        "svc_f1_score_macro=  f1_score(dev_labels, svc_prediction, average='macro')"
      ],
      "metadata": {
        "id": "KMTU3a5BHjwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cahCIOW3WCW5",
        "outputId": "bbfe6cc2-97a1-450e-e61b-407313b28908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accurancy score\n",
            "0.3508771929824561\n",
            "F1 score macro\n",
            "0.18967668746454908\n"
          ]
        }
      ],
      "source": [
        "print('Accurancy score')\n",
        "print(svc_Accurancy)\n",
        "print('F1 score macro')\n",
        "print(svc_f1_score_macro)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VwZxpNlWzLF",
        "outputId": "0983eb93-d4df-4d7e-bc8e-152dd4f3b939"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(data, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu_73qtWW7v3"
      },
      "outputs": [],
      "source": [
        "knn_label_predict = knn.predict(dev)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_Accurancy=accuracy_score(dev_labels , knn_label_predict)\n",
        "knn_f1_score_macro =f1_score(dev_labels, knn_label_predict, average='macro')"
      ],
      "metadata": {
        "id": "0Y7QYqLCJMD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEmRCbmOXLNl",
        "outputId": "8e17e04a-4418-4203-f9a1-c4c172076037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accurancy score\n",
            "0.47368421052631576\n",
            "F1 score macro\n",
            "0.27397047397047397\n"
          ]
        }
      ],
      "source": [
        "print('Accurancy score')\n",
        "print(knn_Accurancy)\n",
        "print('F1 score macro')\n",
        "print(knn_f1_score_macro)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ieFOuUPZD4I"
      },
      "outputs": [],
      "source": [
        "del knn\n",
        "del svc\n",
        "del data\n",
        "del dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPjiP4jp_vFA"
      },
      "outputs": [],
      "source": [
        "def map_fn(flags, train_dataset, dev_dataset, save_path):\n",
        "    ## Setup \n",
        "\n",
        "    # Sets a common random seed - both for initialization and ensuring graph is the same\n",
        "    random.seed(flags['seed'])\n",
        "    np.random.seed(flags['seed'])\n",
        "    torch.manual_seed(flags['seed'])\n",
        "    torch.cuda.manual_seed_all(flags['seed'])\n",
        "\n",
        "    # GPU\n",
        "    # If there's a GPU available...\n",
        "    if torch.cuda.is_available():    \n",
        "        # Tell PyTorch to use the GPU.    \n",
        "        device = torch.device(\"cuda\")\n",
        "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    # If not...\n",
        "    else:\n",
        "        print('No GPU available, using the CPU instead.')\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "  \n",
        "  # Creates dataloaders, which load data in batches\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        sampler = torch.utils.data.RandomSampler(train_dataset),\n",
        "        batch_size=flags['batch_size'])\n",
        "\n",
        "    dev_loader = torch.utils.data.DataLoader(\n",
        "        dev_dataset,\n",
        "        sampler = torch.utils.data.SequentialSampler(dev_dataset),\n",
        "        batch_size=flags['batch_size'])\n",
        "  \n",
        "\n",
        "    ## Network, optimizer, and loss function creation\n",
        "    print('Loading...')\n",
        "    rec_model = REClassifier(flags)\n",
        "    rec_model.to(device)\n",
        " \n",
        "    print('Finish')\n",
        "\n",
        "    \n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = AdamW(rec_model.parameters(), lr=flags['linear_lr'], betas=flags['linear_betas'], \\\n",
        "                      eps=flags['linear_eps'], weight_decay=flags['linear_weight_decay'])\n",
        "\n",
        "    lambda2 = lambda epoch: float(flags['linear_lr_schedule_rate']) ** epoch\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda2)\n",
        "\n",
        "\n",
        "    ## Trains\n",
        "    rec_model.train()\n",
        "\n",
        "    gobal_train_start = time.time()\n",
        "    train_accuracy_score_history=[]\n",
        "    \n",
        "    dev_accuracy_score_history = []\n",
        "    dev_f1_score_macro_history=[]\n",
        "    dev_loss_history = []\n",
        "\n",
        "    for epoch in range(flags['total_epochs']):\n",
        "        print('\\n\\nStart training epoch: ', epoch)\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        train_batch_step = 0\n",
        "        train_loss = 0\n",
        "\n",
        "        train_predict_lst = []\n",
        "        train_target_lst = []\n",
        "\n",
        "        for batch_num, batch in enumerate(train_loader):\n",
        "            batch_start_time = time.time()\n",
        "\n",
        "\n",
        "            pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, targets = \\\n",
        "                batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), batch[4].to(device)\n",
        "\n",
        "            # Acquires the network's best guesses at each class\n",
        "            output = rec_model(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids)\n",
        "\n",
        "            # Computes loss\n",
        "            loss = loss_fn(output, targets) \n",
        "            train_loss += loss.item()\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(rec_model.parameters(), flags['clip_grad_norm_rate'])\n",
        "            \n",
        "            optimizer.step()\n",
        "\n",
        "            if (train_batch_step % flags['log_batch'] == 0):\n",
        "                duration = time.time() - batch_start_time\n",
        "                print(duration, ' - epoch: ', epoch, ' - batch: ', train_batch_step, ' - current_batch_loss: ', loss.item(), ' - current lr: ', str(scheduler.get_last_lr()[0]))\n",
        "\n",
        "            train_batch_step += 1\n",
        "\n",
        "            train_predict_lst.append(torch.argmax(output, 1))\n",
        "            train_target_lst.append(targets)\n",
        "        \n",
        "\n",
        "        print('\\n\\nFinish training epoch: ', epoch, 'after: ', (time.time() - epoch_start_time))\n",
        "        \n",
        "        train_predict_lst = torch.cat(train_predict_lst).to(torch.device(\"cpu\"))\n",
        "        train_target_lst = torch.cat(train_target_lst).to(torch.device(\"cpu\"))\n",
        "        train_accuracy = accuracy_score(list(train_target_lst), list(train_predict_lst))\n",
        "        \n",
        "        print('train-accuracy: ', train_accuracy)\n",
        "        print('Avg train_loss per batch: ', train_loss/train_batch_step)\n",
        "\n",
        "        if ((epoch + 1) % int(flags['linear_lr_schedule_epoch'])) == 0:\n",
        "            scheduler.step()\n",
        "\n",
        "        print('\\nEvaluating on dev set...')\n",
        "        eval_start_time = time.time()\n",
        "\n",
        "        rec_model.eval()\n",
        "\n",
        "        dev_loss = 0\n",
        "        dev_batch_step = 0\n",
        "\n",
        "        dev_predict_lst = []\n",
        "        dev_target_lst = []\n",
        "\n",
        "        \n",
        "        for dev_batch_num, dev_batch in enumerate(dev_loader):\n",
        "            pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, targets = \\\n",
        "                dev_batch[0].to(device), dev_batch[1].to(device), dev_batch[2].to(device), dev_batch[3].to(device), dev_batch[4].to(device)\n",
        "\n",
        "            output = rec_model(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids)\n",
        "\n",
        "            loss = loss_fn(output, targets)\n",
        "            dev_loss += loss.item()\n",
        "            dev_predict_lst.append(torch.argmax(output, 1))\n",
        "            dev_target_lst.append(targets)\n",
        "\n",
        "            dev_batch_step += 1\n",
        "        \n",
        "        dev_predict_lst = torch.cat(dev_predict_lst).to(torch.device(\"cpu\"))\n",
        "        dev_target_lst = torch.cat(dev_target_lst).to(torch.device(\"cpu\"))\n",
        "\n",
        "        dev_accuracy =  accuracy_score(list(dev_target_lst), list(dev_predict_lst))\n",
        "        dev_f1_macro= f1_score(list(dev_target_lst), list(dev_predict_lst), average='macro')\n",
        "\n",
        "        print('Finish eval epoch: ', epoch, ' after: ', (time.time() - eval_start_time))\n",
        "        print('dev-accuracy: ', dev_accuracy)\n",
        "        print('dev-f1-score-macro: ', dev_f1_macro)\n",
        "        print('Avg dev_loss per batch: ', dev_loss/dev_batch_step)\n",
        "\n",
        "        # save new better model\n",
        "        root_model_save_path = save_path\n",
        "        if (epoch == 0):\n",
        "            print('SAVING MODEL AT EPOCH 0 ...')\n",
        "            model_save_path = root_model_save_path + '/rec_model.bin'\n",
        "            torch.save(rec_model.state_dict(), model_save_path)\n",
        "\n",
        "        elif (dev_accuracy > max(dev_accuracy_score_history)):\n",
        "            print('SAVING MODEL')\n",
        "            model_save_path = root_model_save_path + '/rec_model.bin'\n",
        "            torch.save(rec_model.state_dict(), model_save_path)\n",
        "        \n",
        "        elif (dev_f1_macro > max(dev_f1_score_macro_history)):\n",
        "            print('SAVING MODEL')\n",
        "            model_save_path = root_model_save_path + '/rec_model.bin'\n",
        "            torch.save(rec_model.state_dict(), model_save_path)\n",
        "        \n",
        "        train_accuracy_score_history.append(train_accuracy)\n",
        "        dev_accuracy_score_history.append(dev_accuracy)\n",
        "        dev_f1_score_macro_history.append(dev_f1_macro)\n",
        "        dev_loss_history.append(dev_loss/dev_batch_step)\n",
        "\n",
        "\n",
        "\n",
        "    elapsed_train_time = time.time() - gobal_train_start\n",
        "    print(\"Finished training. Train time was:\", elapsed_train_time)\n",
        "\n",
        "    return train_accuracy_score_history, dev_accuracy_score_history,dev_f1_score_macro_history, dev_loss_history\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPsBsVJAAhKj"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "save_path = './rec_model_save' \n",
        "pathlib.Path(save_path).mkdir(parents=False, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2d292dd6d0cf4cb9af8794f7e2bd3552",
            "2eb990f696894f479c1b2a9e9dc069b0",
            "7eb9d5cc0d3b49fab9df80df46e93252",
            "ce5aeb0a0e0d4dc68331141aa135288a",
            "40cbf7bb5e2b4d3486b12009020b521f",
            "108db016f2ac451887b55b76be989ae8",
            "cac60f1d5d49415ba2cd9a9650700d6d",
            "206efd6aad5042ba89d31560bf79ea31",
            "80309b7d2cd44aecb125e26b7033dd04",
            "d05364a395a344cd862a7f59699fdc0d",
            "08e54cac8eb84b0ca20a10c7982da1e4"
          ]
        },
        "id": "T5uXGlNOAshL",
        "outputId": "00e70830-3e12-4b04-df2d-7d15d5fa18fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n",
            "Loading...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d292dd6d0cf4cb9af8794f7e2bd3552",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finish\n",
            "\n",
            "\n",
            "Start training epoch:  0\n",
            "1.2595815658569336  - epoch:  0  - batch:  0  - current_batch_loss:  2.056205987930298  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  0 after:  16.817415952682495\n",
            "train-accuracy:  0.36254980079681276\n",
            "Avg train_loss per batch:  1.5416383519768715\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  0  after:  1.285599708557129\n",
            "dev-accuracy:  0.3157894736842105\n",
            "dev-f1-score-macro:  0.17965517241379308\n",
            "Avg dev_loss per batch:  1.5445303916931152\n",
            "SAVING MODEL AT EPOCH 0 ...\n",
            "\n",
            "\n",
            "Start training epoch:  1\n",
            "1.020958423614502  - epoch:  1  - batch:  0  - current_batch_loss:  1.2805442810058594  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  1 after:  16.36397933959961\n",
            "train-accuracy:  0.5776892430278885\n",
            "Avg train_loss per batch:  1.0313782915472984\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  1  after:  1.2868332862854004\n",
            "dev-accuracy:  0.43859649122807015\n",
            "dev-f1-score-macro:  0.3868027210884354\n",
            "Avg dev_loss per batch:  1.5401591360569\n",
            "SAVING MODEL\n",
            "\n",
            "\n",
            "Start training epoch:  2\n",
            "1.028921365737915  - epoch:  2  - batch:  0  - current_batch_loss:  0.677340030670166  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  2 after:  16.74017834663391\n",
            "train-accuracy:  0.7609561752988048\n",
            "Avg train_loss per batch:  0.7167459167540073\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  2  after:  1.2958104610443115\n",
            "dev-accuracy:  0.40350877192982454\n",
            "dev-f1-score-macro:  0.32999999999999996\n",
            "Avg dev_loss per batch:  1.5033084601163864\n",
            "\n",
            "\n",
            "Start training epoch:  3\n",
            "1.000457763671875  - epoch:  3  - batch:  0  - current_batch_loss:  0.5742961168289185  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  3 after:  16.47714328765869\n",
            "train-accuracy:  0.852589641434263\n",
            "Avg train_loss per batch:  0.5215679127722979\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  3  after:  1.3024840354919434\n",
            "dev-accuracy:  0.5614035087719298\n",
            "dev-f1-score-macro:  0.4263322884012539\n",
            "Avg dev_loss per batch:  1.5632999539375305\n",
            "SAVING MODEL\n",
            "\n",
            "\n",
            "Start training epoch:  4\n",
            "1.015289306640625  - epoch:  4  - batch:  0  - current_batch_loss:  0.41959428787231445  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  4 after:  16.520129919052124\n",
            "train-accuracy:  0.9203187250996016\n",
            "Avg train_loss per batch:  0.34395939111709595\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  4  after:  1.310776948928833\n",
            "dev-accuracy:  0.43859649122807015\n",
            "dev-f1-score-macro:  0.3331157731157731\n",
            "Avg dev_loss per batch:  1.5687785670161247\n",
            "\n",
            "\n",
            "Start training epoch:  5\n",
            "1.005974531173706  - epoch:  5  - batch:  0  - current_batch_loss:  0.255534291267395  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  5 after:  16.523906707763672\n",
            "train-accuracy:  0.9641434262948207\n",
            "Avg train_loss per batch:  0.22475553024560213\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  5  after:  1.309138536453247\n",
            "dev-accuracy:  0.47368421052631576\n",
            "dev-f1-score-macro:  0.3570802005012531\n",
            "Avg dev_loss per batch:  1.5901569500565529\n",
            "\n",
            "\n",
            "Start training epoch:  6\n",
            "1.0197582244873047  - epoch:  6  - batch:  0  - current_batch_loss:  0.2146541178226471  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  6 after:  16.533896446228027\n",
            "train-accuracy:  0.9880478087649402\n",
            "Avg train_loss per batch:  0.14580319123342633\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  6  after:  1.301201581954956\n",
            "dev-accuracy:  0.47368421052631576\n",
            "dev-f1-score-macro:  0.35552178318135763\n",
            "Avg dev_loss per batch:  1.637263037264347\n",
            "\n",
            "\n",
            "Start training epoch:  7\n",
            "1.0220012664794922  - epoch:  7  - batch:  0  - current_batch_loss:  0.14860090613365173  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  7 after:  16.530389308929443\n",
            "train-accuracy:  0.9960159362549801\n",
            "Avg train_loss per batch:  0.0908576708752662\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  7  after:  1.3188679218292236\n",
            "dev-accuracy:  0.45614035087719296\n",
            "dev-f1-score-macro:  0.3396969696969697\n",
            "Avg dev_loss per batch:  1.7205520570278168\n",
            "\n",
            "\n",
            "Start training epoch:  8\n",
            "1.0118885040283203  - epoch:  8  - batch:  0  - current_batch_loss:  0.045582983642816544  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  8 after:  16.529304027557373\n",
            "train-accuracy:  0.9960159362549801\n",
            "Avg train_loss per batch:  0.07855270814616233\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  8  after:  1.3028767108917236\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.38469868173258004\n",
            "Avg dev_loss per batch:  1.7119372189044952\n",
            "\n",
            "\n",
            "Start training epoch:  9\n",
            "1.0015842914581299  - epoch:  9  - batch:  0  - current_batch_loss:  0.05007266253232956  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  9 after:  16.55789351463318\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.04185045580379665\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  9  after:  1.3078556060791016\n",
            "dev-accuracy:  0.49122807017543857\n",
            "dev-f1-score-macro:  0.3785858585858585\n",
            "Avg dev_loss per batch:  1.7192816585302353\n",
            "\n",
            "\n",
            "Start training epoch:  10\n",
            "1.0251247882843018  - epoch:  10  - batch:  0  - current_batch_loss:  0.02452782541513443  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  10 after:  16.564682960510254\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.03053495637141168\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  10  after:  1.3090121746063232\n",
            "dev-accuracy:  0.47368421052631576\n",
            "dev-f1-score-macro:  0.38158558558558553\n",
            "Avg dev_loss per batch:  1.7118379697203636\n",
            "\n",
            "\n",
            "Start training epoch:  11\n",
            "1.014233112335205  - epoch:  11  - batch:  0  - current_batch_loss:  0.02033575251698494  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  11 after:  16.54009222984314\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.02301336679374799\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  11  after:  1.3044054508209229\n",
            "dev-accuracy:  0.49122807017543857\n",
            "dev-f1-score-macro:  0.3630067705359328\n",
            "Avg dev_loss per batch:  1.7431403174996376\n",
            "\n",
            "\n",
            "Start training epoch:  12\n",
            "1.0253582000732422  - epoch:  12  - batch:  0  - current_batch_loss:  0.023634085431694984  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  12 after:  16.53484869003296\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.017715662601403892\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  12  after:  1.3106358051300049\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.4\n",
            "Avg dev_loss per batch:  1.7521570399403572\n",
            "\n",
            "\n",
            "Start training epoch:  13\n",
            "1.0308151245117188  - epoch:  13  - batch:  0  - current_batch_loss:  0.019672898575663567  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  13 after:  16.490196228027344\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.014444533851929009\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  13  after:  1.3118886947631836\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.7700168266892433\n",
            "\n",
            "\n",
            "Start training epoch:  14\n",
            "1.0205740928649902  - epoch:  14  - batch:  0  - current_batch_loss:  0.017218556255102158  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  14 after:  16.538475036621094\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.01218183056334965\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  14  after:  1.3120713233947754\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.7875788137316704\n",
            "\n",
            "\n",
            "Start training epoch:  15\n",
            "1.0123059749603271  - epoch:  15  - batch:  0  - current_batch_loss:  0.009093539789319038  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  15 after:  16.54566717147827\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.010406657063867897\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  15  after:  1.3100636005401611\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.7890816554427147\n",
            "\n",
            "\n",
            "Start training epoch:  16\n",
            "1.0259733200073242  - epoch:  16  - batch:  0  - current_batch_loss:  0.009956230409443378  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  16 after:  16.574025869369507\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.00932747172191739\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  16  after:  1.3048245906829834\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.7998624593019485\n",
            "\n",
            "\n",
            "Start training epoch:  17\n",
            "1.014528512954712  - epoch:  17  - batch:  0  - current_batch_loss:  0.005103787407279015  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  17 after:  16.54673480987549\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.008222596137784421\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  17  after:  1.298699140548706\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8038355186581612\n",
            "\n",
            "\n",
            "Start training epoch:  18\n",
            "1.0246379375457764  - epoch:  18  - batch:  0  - current_batch_loss:  0.008846264332532883  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  18 after:  16.57885193824768\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0072256453859154135\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  18  after:  1.3150646686553955\n",
            "dev-accuracy:  0.49122807017543857\n",
            "dev-f1-score-macro:  0.3630067705359328\n",
            "Avg dev_loss per batch:  1.8206175714731216\n",
            "\n",
            "\n",
            "Start training epoch:  19\n",
            "1.0248336791992188  - epoch:  19  - batch:  0  - current_batch_loss:  0.00655765924602747  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  19 after:  16.520589351654053\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.006587185605894774\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  19  after:  1.3077878952026367\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8236599639058113\n",
            "\n",
            "\n",
            "Start training epoch:  20\n",
            "1.0003793239593506  - epoch:  20  - batch:  0  - current_batch_loss:  0.004311861004680395  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  20 after:  16.558070182800293\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.005833001603605226\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  20  after:  1.3082642555236816\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8337876796722412\n",
            "\n",
            "\n",
            "Start training epoch:  21\n",
            "1.0124013423919678  - epoch:  21  - batch:  0  - current_batch_loss:  0.004759469535201788  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  21 after:  16.537086486816406\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.00534879180486314\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  21  after:  1.3039863109588623\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.841983288526535\n",
            "\n",
            "\n",
            "Start training epoch:  22\n",
            "1.0060038566589355  - epoch:  22  - batch:  0  - current_batch_loss:  0.0031828032806515694  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  22 after:  16.52434253692627\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.004837128239159938\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  22  after:  1.3028199672698975\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8448050767183304\n",
            "\n",
            "\n",
            "Start training epoch:  23\n",
            "1.0041828155517578  - epoch:  23  - batch:  0  - current_batch_loss:  0.00587859470397234  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  23 after:  16.55043625831604\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.004551594553049654\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  23  after:  1.3067517280578613\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8494685292243958\n",
            "\n",
            "\n",
            "Start training epoch:  24\n",
            "1.0242187976837158  - epoch:  24  - batch:  0  - current_batch_loss:  0.005023788660764694  - current lr:  6.561e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  24 after:  16.560762643814087\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0041965522250393406\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  24  after:  1.3078324794769287\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8596380949020386\n",
            "\n",
            "\n",
            "Start training epoch:  25\n",
            "1.0133056640625  - epoch:  25  - batch:  0  - current_batch_loss:  0.002731313230469823  - current lr:  6.561e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  25 after:  16.587120056152344\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.00391519270488061\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  25  after:  1.3039741516113281\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8646514862775803\n",
            "\n",
            "\n",
            "Start training epoch:  26\n",
            "1.0255458354949951  - epoch:  26  - batch:  0  - current_batch_loss:  0.003376609645783901  - current lr:  6.561e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  26 after:  16.564483642578125\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0036123443860560656\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  26  after:  1.3024952411651611\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8638453409075737\n",
            "\n",
            "\n",
            "Start training epoch:  27\n",
            "1.0164144039154053  - epoch:  27  - batch:  0  - current_batch_loss:  0.003241103608161211  - current lr:  6.561e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  27 after:  16.57847023010254\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0033881029376061633\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  27  after:  1.3031854629516602\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8703221753239632\n",
            "\n",
            "\n",
            "Start training epoch:  28\n",
            "1.0255992412567139  - epoch:  28  - batch:  0  - current_batch_loss:  0.0026689493097364902  - current lr:  6.561e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  28 after:  16.57075071334839\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.003219973426894285\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  28  after:  1.304063081741333\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.878559947013855\n",
            "\n",
            "\n",
            "Start training epoch:  29\n",
            "1.0150110721588135  - epoch:  29  - batch:  0  - current_batch_loss:  0.0032339405734091997  - current lr:  6.561e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  29 after:  16.5433566570282\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.003004169564519543\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  29  after:  1.306800127029419\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8836030140519142\n",
            "\n",
            "\n",
            "Start training epoch:  30\n",
            "1.029829502105713  - epoch:  30  - batch:  0  - current_batch_loss:  0.0032117245718836784  - current lr:  5.904900000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  30 after:  16.520764112472534\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.002818632929120213\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  30  after:  1.3012518882751465\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.8848529160022736\n",
            "\n",
            "\n",
            "Start training epoch:  31\n",
            "1.001441478729248  - epoch:  31  - batch:  0  - current_batch_loss:  0.001711703953333199  - current lr:  5.904900000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  31 after:  16.55070185661316\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.002674022543942556\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  31  after:  1.3008346557617188\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8905896916985512\n",
            "\n",
            "\n",
            "Start training epoch:  32\n",
            "1.050736665725708  - epoch:  32  - batch:  0  - current_batch_loss:  0.0022093558218330145  - current lr:  5.904900000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  32 after:  16.560927867889404\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.002554061749833636\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  32  after:  1.3133995532989502\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.8933893144130707\n",
            "\n",
            "\n",
            "Start training epoch:  33\n",
            "1.0135340690612793  - epoch:  33  - batch:  0  - current_batch_loss:  0.002267298521474004  - current lr:  5.904900000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  33 after:  16.52998948097229\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0024303425307152793\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  33  after:  1.31126070022583\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.8999484032392502\n",
            "\n",
            "\n",
            "Start training epoch:  34\n",
            "1.016334056854248  - epoch:  34  - batch:  0  - current_batch_loss:  0.0020708171650767326  - current lr:  5.904900000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  34 after:  16.541388034820557\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.002295909740496427\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  34  after:  1.3037512302398682\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  1.904310293495655\n",
            "\n",
            "\n",
            "Start training epoch:  35\n",
            "1.0302660465240479  - epoch:  35  - batch:  0  - current_batch_loss:  0.0018442271975800395  - current lr:  5.904900000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  35 after:  16.57034158706665\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.002183967924793251\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  35  after:  1.3041844367980957\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.906787909567356\n",
            "\n",
            "\n",
            "Start training epoch:  36\n",
            "1.0224580764770508  - epoch:  36  - batch:  0  - current_batch_loss:  0.0016382269095629454  - current lr:  5.314410000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  36 after:  16.550495147705078\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.002104428604070563\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  36  after:  1.3192579746246338\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9113165438175201\n",
            "\n",
            "\n",
            "Start training epoch:  37\n",
            "1.0220954418182373  - epoch:  37  - batch:  0  - current_batch_loss:  0.0018983067711815238  - current lr:  5.314410000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  37 after:  16.530770778656006\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0020021467134938575\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  37  after:  1.307420253753662\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9141214042901993\n",
            "\n",
            "\n",
            "Start training epoch:  38\n",
            "1.0178515911102295  - epoch:  38  - batch:  0  - current_batch_loss:  0.00142454553861171  - current lr:  5.314410000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  38 after:  16.55832052230835\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.001921408824273385\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  38  after:  1.298229455947876\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9178480580449104\n",
            "\n",
            "\n",
            "Start training epoch:  39\n",
            "1.0191688537597656  - epoch:  39  - batch:  0  - current_batch_loss:  0.0023654024116694927  - current lr:  5.314410000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  39 after:  16.55595898628235\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0018474807147867978\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  39  after:  1.308852195739746\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9194275736808777\n",
            "\n",
            "\n",
            "Start training epoch:  40\n",
            "1.0479717254638672  - epoch:  40  - batch:  0  - current_batch_loss:  0.0025399080477654934  - current lr:  5.314410000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  40 after:  16.528050661087036\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0017912594412337057\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  40  after:  1.3039002418518066\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.924559272825718\n",
            "\n",
            "\n",
            "Start training epoch:  41\n",
            "1.0221281051635742  - epoch:  41  - batch:  0  - current_batch_loss:  0.0010744857136160135  - current lr:  5.314410000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  41 after:  16.540096759796143\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0017305879991909023\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  41  after:  1.3047688007354736\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9272199496626854\n",
            "\n",
            "\n",
            "Start training epoch:  42\n",
            "1.02958083152771  - epoch:  42  - batch:  0  - current_batch_loss:  0.0019502736395224929  - current lr:  4.782969000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  42 after:  16.550227165222168\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.001654520383453928\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  42  after:  1.3023509979248047\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9292300045490265\n",
            "\n",
            "\n",
            "Start training epoch:  43\n",
            "1.0130248069763184  - epoch:  43  - batch:  0  - current_batch_loss:  0.0016295791137963533  - current lr:  4.782969000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  43 after:  16.52553629875183\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0016124785397551022\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  43  after:  1.307084321975708\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9311502650380135\n",
            "\n",
            "\n",
            "Start training epoch:  44\n",
            "1.033630609512329  - epoch:  44  - batch:  0  - current_batch_loss:  0.0025154990144073963  - current lr:  4.782969000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  44 after:  16.560036420822144\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.001549606768094236\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  44  after:  1.307997465133667\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9346065893769264\n",
            "\n",
            "\n",
            "Start training epoch:  45\n",
            "1.007140874862671  - epoch:  45  - batch:  0  - current_batch_loss:  0.0009854144882410765  - current lr:  4.782969000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  45 after:  16.559820413589478\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0014785762650717515\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  45  after:  1.3036723136901855\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9374698773026466\n",
            "\n",
            "\n",
            "Start training epoch:  46\n",
            "1.0230963230133057  - epoch:  46  - batch:  0  - current_batch_loss:  0.0018348956946283579  - current lr:  4.782969000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  46 after:  16.56374478340149\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0014396600163308904\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  46  after:  1.3042659759521484\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.940287709236145\n",
            "\n",
            "\n",
            "Start training epoch:  47\n",
            "1.027860164642334  - epoch:  47  - batch:  0  - current_batch_loss:  0.0011039894307032228  - current lr:  4.782969000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  47 after:  16.57160711288452\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.001392282167216763\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  47  after:  1.3674578666687012\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.944371074438095\n",
            "\n",
            "\n",
            "Start training epoch:  48\n",
            "1.05027437210083  - epoch:  48  - batch:  0  - current_batch_loss:  0.0007020459161140025  - current lr:  4.304672100000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  48 after:  16.583110094070435\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0013364946717047133\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  48  after:  1.2996938228607178\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.948044054210186\n",
            "\n",
            "\n",
            "Start training epoch:  49\n",
            "1.01456880569458  - epoch:  49  - batch:  0  - current_batch_loss:  0.0010294285602867603  - current lr:  4.304672100000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  49 after:  16.559712886810303\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0013210510187491309\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  49  after:  1.2993659973144531\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9496010467410088\n",
            "\n",
            "\n",
            "Start training epoch:  50\n",
            "1.0334105491638184  - epoch:  50  - batch:  0  - current_batch_loss:  0.0007585833081975579  - current lr:  4.304672100000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  50 after:  16.553149461746216\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0012691916308540385\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  50  after:  1.306699275970459\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9494269117712975\n",
            "\n",
            "\n",
            "Start training epoch:  51\n",
            "1.0217983722686768  - epoch:  51  - batch:  0  - current_batch_loss:  0.0011619164142757654  - current lr:  4.304672100000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  51 after:  16.54865860939026\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0012386259440972935\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  51  after:  1.301037073135376\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9527473598718643\n",
            "\n",
            "\n",
            "Start training epoch:  52\n",
            "1.008021354675293  - epoch:  52  - batch:  0  - current_batch_loss:  0.0008823630050756037  - current lr:  4.304672100000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  52 after:  16.57866907119751\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0012057872627337929\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  52  after:  1.3041300773620605\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9559132680296898\n",
            "\n",
            "\n",
            "Start training epoch:  53\n",
            "1.0217540264129639  - epoch:  53  - batch:  0  - current_batch_loss:  0.0012937692226842046  - current lr:  4.304672100000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  53 after:  16.537174940109253\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.00115922311306349\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  53  after:  1.2970833778381348\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.95908672362566\n",
            "\n",
            "\n",
            "Start training epoch:  54\n",
            "1.0153660774230957  - epoch:  54  - batch:  0  - current_batch_loss:  0.0010499930940568447  - current lr:  3.8742048900000015e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  54 after:  16.514963150024414\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0011384136851120275\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  54  after:  1.300156831741333\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9604721367359161\n",
            "\n",
            "\n",
            "Start training epoch:  55\n",
            "1.026073932647705  - epoch:  55  - batch:  0  - current_batch_loss:  0.000933490286115557  - current lr:  3.8742048900000015e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  55 after:  16.55293369293213\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0011119224400317762\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  55  after:  1.3067083358764648\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.963194452226162\n",
            "\n",
            "\n",
            "Start training epoch:  56\n",
            "1.0182569026947021  - epoch:  56  - batch:  0  - current_batch_loss:  0.0017654021503403783  - current lr:  3.8742048900000015e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  56 after:  16.548784017562866\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.001076375770935556\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  56  after:  1.3111741542816162\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.963842250406742\n",
            "\n",
            "\n",
            "Start training epoch:  57\n",
            "1.0015392303466797  - epoch:  57  - batch:  0  - current_batch_loss:  0.0006951910327188671  - current lr:  3.8742048900000015e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  57 after:  16.570111751556396\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0010637334453349467\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  57  after:  1.317439079284668\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.967107318341732\n",
            "\n",
            "\n",
            "Start training epoch:  58\n",
            "1.0113766193389893  - epoch:  58  - batch:  0  - current_batch_loss:  0.0007434082799591124  - current lr:  3.8742048900000015e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  58 after:  16.560080528259277\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0010363442488596775\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  58  after:  1.3055002689361572\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9689969643950462\n",
            "\n",
            "\n",
            "Start training epoch:  59\n",
            "1.0185956954956055  - epoch:  59  - batch:  0  - current_batch_loss:  0.0008527489262633026  - current lr:  3.8742048900000015e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  59 after:  16.6103937625885\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0010130874798051082\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  59  after:  1.3032708168029785\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.970329537987709\n",
            "\n",
            "\n",
            "Start training epoch:  60\n",
            "1.0072646141052246  - epoch:  60  - batch:  0  - current_batch_loss:  0.0012834337539970875  - current lr:  3.486784401000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  60 after:  16.554960012435913\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0009871041293081362\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  60  after:  1.3032784461975098\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9714049249887466\n",
            "\n",
            "\n",
            "Start training epoch:  61\n",
            "1.0140879154205322  - epoch:  61  - batch:  0  - current_batch_loss:  0.0013629781315103173  - current lr:  3.486784401000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  61 after:  16.5925395488739\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0009566617791278986\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  61  after:  1.3044390678405762\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9744882360100746\n",
            "\n",
            "\n",
            "Start training epoch:  62\n",
            "1.0228216648101807  - epoch:  62  - batch:  0  - current_batch_loss:  0.0011933507630601525  - current lr:  3.486784401000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  62 after:  16.555962562561035\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0009447215488762595\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  62  after:  1.2968242168426514\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9760260730981827\n",
            "\n",
            "\n",
            "Start training epoch:  63\n",
            "1.006824016571045  - epoch:  63  - batch:  0  - current_batch_loss:  0.0010282363509759307  - current lr:  3.486784401000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  63 after:  16.5348858833313\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0009219975199812325\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  63  after:  1.3080894947052002\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9776106104254723\n",
            "\n",
            "\n",
            "Start training epoch:  64\n",
            "1.0056636333465576  - epoch:  64  - batch:  0  - current_batch_loss:  0.0007860679761506617  - current lr:  3.486784401000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  64 after:  16.509975910186768\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0009036642877617851\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  64  after:  1.3139641284942627\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9799500852823257\n",
            "\n",
            "\n",
            "Start training epoch:  65\n",
            "1.0263416767120361  - epoch:  65  - batch:  0  - current_batch_loss:  0.0007058893097564578  - current lr:  3.486784401000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  65 after:  16.549030780792236\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.000884888910150039\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  65  after:  1.314162015914917\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9822193160653114\n",
            "\n",
            "\n",
            "Start training epoch:  66\n",
            "1.021923542022705  - epoch:  66  - batch:  0  - current_batch_loss:  0.000700071977917105  - current lr:  3.138105960900001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  66 after:  16.547394514083862\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0008678776248416398\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  66  after:  1.3051652908325195\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9836488217115402\n",
            "\n",
            "\n",
            "Start training epoch:  67\n",
            "1.0361974239349365  - epoch:  67  - batch:  0  - current_batch_loss:  0.0013825604692101479  - current lr:  3.138105960900001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  67 after:  16.55753469467163\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0008632109529571608\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  67  after:  1.3053703308105469\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9850720167160034\n",
            "\n",
            "\n",
            "Start training epoch:  68\n",
            "1.0374784469604492  - epoch:  68  - batch:  0  - current_batch_loss:  0.0012417391408234835  - current lr:  3.138105960900001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  68 after:  16.559884786605835\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0008410906284552766\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  68  after:  1.307154893875122\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9858127981424332\n",
            "\n",
            "\n",
            "Start training epoch:  69\n",
            "1.0190784931182861  - epoch:  69  - batch:  0  - current_batch_loss:  0.0007296421681530774  - current lr:  3.138105960900001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  69 after:  16.56477952003479\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0008184983216779074\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  69  after:  1.3152320384979248\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.987204559147358\n",
            "\n",
            "\n",
            "Start training epoch:  70\n",
            "1.0269668102264404  - epoch:  70  - batch:  0  - current_batch_loss:  0.0009098397567868233  - current lr:  3.138105960900001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  70 after:  16.5981707572937\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0008083463944785763\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  70  after:  1.303743600845337\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.988255798816681\n",
            "\n",
            "\n",
            "Start training epoch:  71\n",
            "1.0396549701690674  - epoch:  71  - batch:  0  - current_batch_loss:  0.0006948546506464481  - current lr:  3.138105960900001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  71 after:  16.552711963653564\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0007882884965511039\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  71  after:  1.2990148067474365\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9917790964245796\n",
            "\n",
            "\n",
            "Start training epoch:  72\n",
            "1.0205366611480713  - epoch:  72  - batch:  0  - current_batch_loss:  0.0005095062078908086  - current lr:  2.8242953648100014e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  72 after:  16.522346019744873\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0007727417360001709\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  72  after:  1.306217908859253\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.99264694750309\n",
            "\n",
            "\n",
            "Start training epoch:  73\n",
            "1.0192346572875977  - epoch:  73  - batch:  0  - current_batch_loss:  0.0007559253717772663  - current lr:  2.8242953648100014e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  73 after:  16.526938676834106\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0007702651964791585\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  73  after:  1.3048765659332275\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9931206330657005\n",
            "\n",
            "\n",
            "Start training epoch:  74\n",
            "1.0169587135314941  - epoch:  74  - batch:  0  - current_batch_loss:  0.0006738559459336102  - current lr:  2.8242953648100014e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  74 after:  16.541524648666382\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0007504964305553585\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  74  after:  1.3117175102233887\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9956767782568932\n",
            "\n",
            "\n",
            "Start training epoch:  75\n",
            "1.0159387588500977  - epoch:  75  - batch:  0  - current_batch_loss:  0.0007725463947281241  - current lr:  2.8242953648100014e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  75 after:  16.5065176486969\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0007361993211816298\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  75  after:  1.3008971214294434\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.37204635876145997\n",
            "Avg dev_loss per batch:  1.9980390965938568\n",
            "\n",
            "\n",
            "Start training epoch:  76\n",
            "1.0085124969482422  - epoch:  76  - batch:  0  - current_batch_loss:  0.0008990010246634483  - current lr:  2.8242953648100014e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  76 after:  16.56771206855774\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0007271580543601885\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  76  after:  1.3017678260803223\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.3816666666666667\n",
            "Avg dev_loss per batch:  1.9988977685570717\n",
            "\n",
            "\n",
            "Start training epoch:  77\n",
            "1.0229859352111816  - epoch:  77  - batch:  0  - current_batch_loss:  0.00041760652675293386  - current lr:  2.8242953648100014e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  77 after:  16.54340386390686\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0007206217560451478\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  77  after:  1.318497896194458\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.38304552590266877\n",
            "Avg dev_loss per batch:  1.9996992275118828\n",
            "\n",
            "\n",
            "Start training epoch:  78\n",
            "1.0059094429016113  - epoch:  78  - batch:  0  - current_batch_loss:  0.0006529407110065222  - current lr:  2.541865828329001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  78 after:  16.542250633239746\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0007041632088657934\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  78  after:  1.317406415939331\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.38304552590266877\n",
            "Avg dev_loss per batch:  2.000700630247593\n",
            "\n",
            "\n",
            "Start training epoch:  79\n",
            "1.0175633430480957  - epoch:  79  - batch:  0  - current_batch_loss:  0.000995870097540319  - current lr:  2.541865828329001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  79 after:  16.524290561676025\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.000689417003741255\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  79  after:  1.302412748336792\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.38304552590266877\n",
            "Avg dev_loss per batch:  2.0028437599539757\n",
            "\n",
            "\n",
            "Start training epoch:  80\n",
            "1.0117590427398682  - epoch:  80  - batch:  0  - current_batch_loss:  0.0004678079567383975  - current lr:  2.541865828329001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  80 after:  16.550597667694092\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006813483360019745\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  80  after:  1.310750961303711\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.38304552590266877\n",
            "Avg dev_loss per batch:  2.004340372979641\n",
            "\n",
            "\n",
            "Start training epoch:  81\n",
            "1.011368989944458  - epoch:  81  - batch:  0  - current_batch_loss:  0.0006905629415996373  - current lr:  2.541865828329001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  81 after:  16.53465723991394\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006740574935975019\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  81  after:  1.3133423328399658\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.38304552590266877\n",
            "Avg dev_loss per batch:  2.0057304427027702\n",
            "\n",
            "\n",
            "Start training epoch:  82\n",
            "1.0513250827789307  - epoch:  82  - batch:  0  - current_batch_loss:  0.0010959929786622524  - current lr:  2.541865828329001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  82 after:  16.51092290878296\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006654101744061336\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  82  after:  1.3166203498840332\n",
            "dev-accuracy:  0.5263157894736842\n",
            "dev-f1-score-macro:  0.38304552590266877\n",
            "Avg dev_loss per batch:  2.0066994577646255\n",
            "\n",
            "\n",
            "Start training epoch:  83\n",
            "1.0193004608154297  - epoch:  83  - batch:  0  - current_batch_loss:  0.000523640657775104  - current lr:  2.541865828329001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  83 after:  16.55633044242859\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006557844135386404\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  83  after:  1.3000538349151611\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.014133036136627\n",
            "\n",
            "\n",
            "Start training epoch:  84\n",
            "1.0160865783691406  - epoch:  84  - batch:  0  - current_batch_loss:  0.0006336795049719512  - current lr:  2.287679245496101e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  84 after:  16.536423683166504\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006432773916458245\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  84  after:  1.3002572059631348\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.017358772456646\n",
            "\n",
            "\n",
            "Start training epoch:  85\n",
            "1.0074007511138916  - epoch:  85  - batch:  0  - current_batch_loss:  0.00047599428216926754  - current lr:  2.287679245496101e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  85 after:  16.537809371948242\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006405289386748336\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  85  after:  1.306408166885376\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.0191573053598404\n",
            "\n",
            "\n",
            "Start training epoch:  86\n",
            "1.023155689239502  - epoch:  86  - batch:  0  - current_batch_loss:  0.0006072423420846462  - current lr:  2.287679245496101e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  86 after:  16.544602394104004\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006287960932240821\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  86  after:  1.3027915954589844\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.0222359225153923\n",
            "\n",
            "\n",
            "Start training epoch:  87\n",
            "1.0155448913574219  - epoch:  87  - batch:  0  - current_batch_loss:  0.0005270277615636587  - current lr:  2.287679245496101e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  87 after:  16.556148529052734\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006233582553250017\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  87  after:  1.3097200393676758\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.023180790245533\n",
            "\n",
            "\n",
            "Start training epoch:  88\n",
            "1.0096092224121094  - epoch:  88  - batch:  0  - current_batch_loss:  0.00037442275788635015  - current lr:  2.287679245496101e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  88 after:  16.53671383857727\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006166206640045857\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  88  after:  1.300173044204712\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.0266965702176094\n",
            "\n",
            "\n",
            "Start training epoch:  89\n",
            "0.9990630149841309  - epoch:  89  - batch:  0  - current_batch_loss:  0.00047978866496123374  - current lr:  2.287679245496101e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  89 after:  16.52253293991089\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006052749413356651\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  89  after:  1.3056857585906982\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.02859153598547\n",
            "\n",
            "\n",
            "Start training epoch:  90\n",
            "1.0226905345916748  - epoch:  90  - batch:  0  - current_batch_loss:  0.000662934617139399  - current lr:  2.058911320946491e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  90 after:  16.524896144866943\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0006025691436661873\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  90  after:  1.3187065124511719\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.029855154454708\n",
            "\n",
            "\n",
            "Start training epoch:  91\n",
            "0.9958024024963379  - epoch:  91  - batch:  0  - current_batch_loss:  0.0005158353014849126  - current lr:  2.058911320946491e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  91 after:  16.55034852027893\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0005887007228011498\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  91  after:  1.3027889728546143\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.0303488448262215\n",
            "\n",
            "\n",
            "Start training epoch:  92\n",
            "1.0058250427246094  - epoch:  92  - batch:  0  - current_batch_loss:  0.00047937576891854405  - current lr:  2.058911320946491e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  92 after:  16.53147840499878\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0005871214625585708\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  92  after:  1.305079460144043\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.0313708633184433\n",
            "\n",
            "\n",
            "Start training epoch:  93\n",
            "1.03596830368042  - epoch:  93  - batch:  0  - current_batch_loss:  0.0007283632294274867  - current lr:  2.058911320946491e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  93 after:  16.55988049507141\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0005743028759752633\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  93  after:  1.3049547672271729\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.032861717045307\n",
            "\n",
            "\n",
            "Start training epoch:  94\n",
            "1.0192599296569824  - epoch:  94  - batch:  0  - current_batch_loss:  0.000855210586450994  - current lr:  2.058911320946491e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  94 after:  16.541977882385254\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0005707224427169422\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  94  after:  1.3092210292816162\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.0345490276813507\n",
            "\n",
            "\n",
            "Start training epoch:  95\n",
            "1.007166862487793  - epoch:  95  - batch:  0  - current_batch_loss:  0.0006694637704640627  - current lr:  2.058911320946491e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  95 after:  16.505584955215454\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0005695166910300031\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  95  after:  1.3053374290466309\n",
            "dev-accuracy:  0.49122807017543857\n",
            "dev-f1-score-macro:  0.3630067705359328\n",
            "Avg dev_loss per batch:  2.0354489013552666\n",
            "\n",
            "\n",
            "Start training epoch:  96\n",
            "1.0100083351135254  - epoch:  96  - batch:  0  - current_batch_loss:  0.0004131646710447967  - current lr:  1.8530201888518418e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  96 after:  16.537726879119873\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0005536738372029504\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  96  after:  1.2951138019561768\n",
            "dev-accuracy:  0.49122807017543857\n",
            "dev-f1-score-macro:  0.3630067705359328\n",
            "Avg dev_loss per batch:  2.0364976599812508\n",
            "\n",
            "\n",
            "Start training epoch:  97\n",
            "1.0215425491333008  - epoch:  97  - batch:  0  - current_batch_loss:  0.00042401085374876857  - current lr:  1.8530201888518418e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  97 after:  16.588263750076294\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0005548142062252737\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  97  after:  1.2970433235168457\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.0364325866103172\n",
            "\n",
            "\n",
            "Start training epoch:  98\n",
            "1.016169548034668  - epoch:  98  - batch:  0  - current_batch_loss:  0.0005765282548964024  - current lr:  1.8530201888518418e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  98 after:  16.542211771011353\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.000541369592610863\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  98  after:  1.3078012466430664\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.037163332104683\n",
            "\n",
            "\n",
            "Start training epoch:  99\n",
            "1.0066940784454346  - epoch:  99  - batch:  0  - current_batch_loss:  0.000623746425844729  - current lr:  1.8530201888518418e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  99 after:  16.53984808921814\n",
            "train-accuracy:  1.0\n",
            "Avg train_loss per batch:  0.0005436324818219873\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  99  after:  1.2946112155914307\n",
            "dev-accuracy:  0.5087719298245614\n",
            "dev-f1-score-macro:  0.3728968903436989\n",
            "Avg dev_loss per batch:  2.037546344101429\n",
            "Finished training. Train time was: 1795.1650836467743\n"
          ]
        }
      ],
      "source": [
        "train_accuracy_score_history, dev_accuracy_score_history,dev_f1_score_macro_history,dev_loss_history = map_fn(flags,train_dataset, dev_dataset, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_Accuracy=max(dev_accuracy_score_history)\n",
        "dev_f1_macro=max(dev_f1_score_macro_history)\n"
      ],
      "metadata": {
        "id": "VEOKyqFJQcZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label=[\"SVC\",\"KNN\",\"Multi\"]\n",
        "values=[svc_Accurancy,knn_Accurancy,dev_Accuracy]\n",
        "plt.bar(label,values,width=0.2)\n",
        "plt.title(\"Accurancy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "u5WUXu2BRnTl",
        "outputId": "54f4f33d-ec53-46df-9920-c118ca6778ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label=[\"SVC\",\"KNN\",\"Multi\"]\n",
        "values=[svc_f1_score_macro,knn_f1_score_macro,dev_f1_macro]\n",
        "plt.bar(label,values,width=0.2)\n",
        "plt.title(\"F1-score macro\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "QZyCDAgOR7w8",
        "outputId": "4ce587dc-ed2c-47c6-b417-08fa6eba1757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_epoch=flags['total_epochs']\n",
        "epoch=[i for i in range(total_epoch)]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epoch, train_accuracy_score_history, label='train')\n",
        "plt.plot(epoch, dev_accuracy_score_history, label='dev')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('%')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "U9WEFK15lqI3",
        "outputId": "104f5ac9-3d55-45d3-caa5-a4235999a578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU9Z3/8dcnIeRCuIaASJBEpQpVQW51q7VWawvqgq0X1LW37ZbHrrq127q7uu1aS9tf7dbtbu3atd6qtipeWitqlK1WbNWqBEXlftUSkBIuARJym+Tz++OcgXGSQAI5GZjzfj4ePDJz5mTmcxiY93wv53vM3RERkfjKyXQBIiKSWQoCEZGYUxCIiMScgkBEJOYUBCIiMdcn0wV019ChQ728vDzTZYiIHFEWLVq01d1LO3rsiAuC8vJyqqqqMl2GiMgRxcze6+wxdQ2JiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMRRYEZnaPmW0xsyWdPG5mdquZrTGzt81sYlS1iIhI56JsEdwLTNvP49OBMeGf2cD/RliLiIh0IrLzCNz9D2ZWvp9dZgL3e7AO9qtmNsjMRrj7+1HV1Ft2N7bwzJLNVG/fk+lSRCSLnDN2OONHDerx583kCWUjgQ0p96vDbe2CwMxmE7QaOOaYY3qluK5a9N4ONoQf+K1tzktrtvLMkvdpbGkDwCyT1YlINhk2oCDrgqDL3P0O4A6AyZMnHxZX0mlOtPGDZ5bzi5ff/cD2/gV9uGhiGRdPKmPCqEGYkkBEDnOZDIKNwKiU+2XhtsPehu17uObBN3ireidfOr2cz502eu8H/oiBBRTk5Wa4QhGRrstkEMwDrjGzucBHgJ1HwvjA7sYWLrztZZpb27j9yklMO+moTJckInJIIgsCM3sIOAsYambVwLeBPAB3vx2oBM4D1gB7gC9FVUtPenjhBrbVN/P4VR/l1GMGZ7ocEZFDFuWsocsP8LgDV0f1+lFItLbxi5ffZWrFEIWAiGQNnVncDfOX/oWNtQ383RkVmS5FRKTHKAi64a6X1jG6pIhzxg7PdCkiIj1GQdBFi97bwZt/ruVvT68gN0dTQkUkeygIuujul9YxoKAPF08qy3QpIiI9SkHQBdvqmnh2yWYu/8gx9Ms/Is7BExHpMgVBF7y+fjttDp/+sM4ZEJHsoyDogtfWb6cwL5eTjh6Y6VJERHqcgqALXlu/nYmjB9G3j/66RCT76JPtAHbuaWHF5l1MLS/JdCkiIpFQEBxA1XvbcYePHDsk06WIiERCQXAAr6/fTt/cHCZEsAa4iMjhQEFwAK+t3874UQO1tLSIZC0FwX7UNyV4Z+NOplaoW0hEspeCYD/e+PMOWtucqRUaKBaR7KUg2I/X128nN8eYNFpLTotI9lIQ7Mdr67dz0tEDKNayEiKSxRQEnWhsaWXxhlqND4hI1lMQdGLl5t00J9qYqCuRiUiWUxB0Ym1NHQBjhvfPcCUiItFSEHRibU0dfXKM0SVFmS5FRCRSkQaBmU0zs5VmtsbMru/g8dFm9ryZvW1mC8zssLnqy5otdYwuKSIvV1kpItktsk85M8sFbgOmA+OAy81sXNputwD3u/spwBzgB1HV011ra+o5rrQ402WIiEQuyq+7U4E17r7O3ZuBucDMtH3GAb8Pb7/QweMZ0dLaxnvb6jlumIJARLJflEEwEtiQcr863JbqLeCz4e3PAP3NrN1pvGY228yqzKyqpqYmkmJTbdi+h5ZW53i1CEQkBjLdAX4d8HEzexP4OLARaE3fyd3vcPfJ7j65tLQ08qLWbAlmDKlFICJxEOUpsxuBUSn3y8Jte7n7JsIWgZkVAxe5e22ENXXJ2pp6AI4t7ZfhSkREohdli2AhMMbMKsysL3AZMC91BzMbambJGm4A7omwni5bW1PHsP75DCjIy3QpIiKRiywI3D0BXAPMB5YDj7j7UjObY2Yzwt3OAlaa2SpgOPD9qOrpjrU1dRyvbiERiYlIV1Nz90qgMm3bjSm3HwMei7KG7nJ31myp48IJ6ePaIiLZKdODxYedmromdjcmOE7jAyISEwqCNGu3BAPFmjEkInGhIEiTXGxOYwQiEhcKgjRra+oo6pvLUQMKMl2KiEivUBCkWbOljuNKizGzTJciItIrFARp1tXUa6BYRGJFQZBiT3OCjbUNGh8QkVhREKRYt3dpCQWBiMSHgiBF9Y49ABwzRFclE5H4UBCk2FTbCMDIQYUZrkREpPcoCFJsqm2gMC+XQUVabE5E4kNBkGLTzgZGDCrQ1FERiRUFQYpNtY3qFhKR2FEQpNhU28DRAxUEIhIvCoJQU6KVLbubOFotAhGJGQVB6C87mwAYMUhrDIlIvCgIQpt2NgCaOioi8aMgCG2qDYJAXUMiEjcKglAyCEYMVNeQiMSLgiC0sbaRkn59KcjLzXQpIiK9KtIgMLNpZrbSzNaY2fUdPH6Mmb1gZm+a2dtmdl6U9ezP+zsb1C0kIrEUWRCYWS5wGzAdGAdcbmbj0nb7FvCIu58KXAb8LKp6DmRTbQNHa8aQiMRQlC2CqcAad1/n7s3AXGBm2j4ODAhvDwQ2RVjPfm2qbWSETiYTkRiKMghGAhtS7leH21LdBFxpZtVAJfCPHT2Rmc02syozq6qpqenxQnc1tlDXlNDUURGJpUwPFl8O3OvuZcB5wC/NrF1N7n6Hu09298mlpaU9XoSmjopInEUZBBuBUSn3y8Jtqb4MPALg7n8CCoChEdbUoX1BoDECEYmfKINgITDGzCrMrC/BYPC8tH3+DJwDYGZjCYKg5/t+DmBjeEEatQhEJI4iCwJ3TwDXAPOB5QSzg5aa2RwzmxHu9g3gK2b2FvAQ8EV396hq6sz7tQ3k5Rqlxfm9/dIiIhnXJ8ond/dKgkHg1G03ptxeBpweZQ1dsam2gaMGFpCTowvSiEj8ZHqw+LCwqbZR1yEQkdhSEAAba3VWsYjEV+yDoLXN+cuuRs0YEpHYin0Q1OxuItHmahGISGzFPgg2Js8h0BiBiMRU7IOgZndwDsHwAeoaEpF4in0Q7GpIADCgMNKZtCIihy0FQWMLAP0L8jJciYhIZsQ+COqaghZBcb5aBCIST7EPgt2NCfr1zSVXZxWLSEwpCBpb1C0kIrGmIGhM0L9A3UIiEl8KAgWBiMScgkBdQyIScwoCtQhEJOZiHwS7GhNqEYhIrMU+COqaWtQiEJFYi3UQtLS20djSRn+dTCYiMRbrINjdGJxVrBaBiMRZzINA6wyJiEQaBGY2zcxWmtkaM7u+g8f/y8wWh39WmVltlPWkU4tARAQi+wQ0s1zgNuBcoBpYaGbz3H1Zch93/6eU/f8RODWqejqilUdFRKJtEUwF1rj7OndvBuYCM/ez/+XAQxHW045aBCIi0QbBSGBDyv3qcFs7ZjYaqAB+38njs82sysyqampqeqxABYGIyOEzWHwZ8Ji7t3b0oLvf4e6T3X1yaWlpj71onbqGREQiDYKNwKiU+2Xhto5cRi93C4FaBCIiEG0QLATGmFmFmfUl+LCfl76TmZ0IDAb+FGEtHdrdlKAgL4e83MOlYSQi0vsi+wR09wRwDTAfWA484u5LzWyOmc1I2fUyYK67e1S1dEYrj4qIRDh9FMDdK4HKtG03pt2/Kcoa9meXVh4VETlsBoszYndjQusMiUjsxTwI1DUkIhLzIFDXkIhIrIOgTkEgItK9IDCz08zsWTNbYGYXRlVUb1HXkIjIAWYNmdlR7r45ZdPXgc8ABrwG/DbC2iLV2ubUN7eqRSAisXegT8HbzewN4D/cvRGoBS4G2oBdURcXpbq9ZxWrRSAi8bbfriF3vxB4E3jKzD4PfA3IB0qAI7praO8S1Jo+KiIxd8AxAnd/Evg0MBB4HFjl7re6e88tA5oBWmdIRCSw3yAwsxlm9gLwLLAEmAXMNLO5ZnZcbxQYFV2mUkQkcKCvw98juMBMITDf3acC3zCzMcD3CdYJOiKpRSAiEjjQp+BO4LNAEbAludHdV3MEhwBAXZOCQEQEDjxG8BmCgeE+wBXRl9N71DUkIhLY79dhd98K/LSXaulVu9Q1JCICxHiJid2NCfJyjfw+sf0rEBEBYh0EwfISZpbpUkREMirGQaAF50REINZB0KIgEBEh1kGQoH++ZgyJiMQ2COqa1DUkIgIRB4GZTTOzlWa2xsyu72SfS81smZktNbMHo6wn1e7GBMUKAhGRA55ZfNDMLBe4DTgXqAYWmtk8d1+Wss8Y4AbgdHffYWbDoqon3a7GFgboZDIRkUhbBFOBNe6+zt2bgbnAzLR9vgLc5u47ANx9C72grc3VNSQiEooyCEYCG1LuV4fbUn0I+JCZvWxmr5rZtI6eyMxmm1mVmVXV1Bz66tf1zQncdVaxiAhkfrC4DzAGOAu4HLjTzAal7+Tud7j7ZHefXFpaesgvultXJxMR2SvKINgIjEq5XxZuS1UNzHP3FndfD6wiCIZIaQlqEZF9ogyChcAYM6sws74Ey1bPS9vntwStAcxsKEFX0boIawK08qiISKrIgsDdE8A1wHxgOfCIuy81szlmNiPcbT6wzcyWAS8A/+zu26KqKWl3eC2CYl2vWEQkuumjAO5eCVSmbbsx5bYDXw//9Jpk19AAdQ2JiGR8sDgj6sIg0AllIiIxDYL6sGuon7qGRETiGQTJ6xX366sgEBGJZRDsaU5QmJdLbo4uSiMiEssgqGtqpV9+bvsHGnbAw5+D+q29X5SISIbEMgjqmxIdjw9sfAOWz4M/v9r7RYmIZEgsg2BPc6Lj8YHG2uBn/aGvZyQicqSIZRDUNSU67xoCBYGIxEosg6C+qbXjrqEGtQhEJH7iGQTNnYwRqGtIRGIonkHQlKBf3466hpJBoFlDIhIfMQ2CzrqGNEYgIvETuyBwd+qbEx2vPNq4M/hZ1ytXzBQROSzELggaWlpx72SdoWTXUMN2aE30bmEiIhkSu8V29q0ztJ/powB7tkH/4d178jd+CYNGwbFnHXR9WaNhB7zyU/jIP0BxyuVFW1vgD7fAyRfD0P1cjK7qHlj/x+jrlMywHDjtKiib9MHtix+E1b/rmdfoPwLO/hb0LeqZ58tisQuCPU2tQCctgsZaGDgKdm4Ixgm6EwTu8H/fhCHHwuwFPVLrEe13N8Ib98OO9+Diu/dtf/Vn8OLNsHo+/N3zkNNBIL/3Cjz1TzBgJOTpP3FWqtsSnMF/zevQt1+wbdNieOJqKB4OfYsP8QUclv4G8grgnBsPvHvMxS4I6jpbgrq1BZrroGzKviDojvqtwRjDpjdh1/swYEQPVXwE2rAwCIGBx8CSx2Di5+HYj8POjbDgh8H2TW/Conthypc/+LutLfD0N4JAvvq1fR8Skl3e+xP8Yhr84UfwyZugrS1434uGwlWvQuGgQ3+N38yGl2+F8Zfvv/Up8RsjqO9sCerkQHHyH0x3g2Db6n23Vz17kNVlgbZWePrrQbN89gswaDRUXgeJZph/A3grfPFJKP8YPD+n/VTd134OW5bBtB8oBLLZ6L+C8VfAK/8DNavgzfthYxV86rs9EwIA534X8gqDf3/uPfOcWSp2QbCnOdk1lNYlkRwfKDnIINgaBkH+AFj5zCFUeIRbeDdsfjv4IO83FM67Bbaugke/AMuegDOvg8HlwfbmOvjdt/f97q5NsOAHMOZTcOIFGTsE6SXnzgn67+f9Izx3E4w+HU6Z1XPP3384nP3vsG4BLH285543C8W2a6jd9NHkjKHBoyEn7yBaBGsgNz9ohi66F5rrD/yNdvOSYF9v695rJeUXw+lfg6Ih+7a1tQX98NvXHdxzHqp3HoNjPwHjLgzufyj8UF/xFJQcDx/9arB92InwV1fDyz8BI/i7e39x0DU0/YdgulZE1isuDfrvn/4G5PSB8/+z59/3KV+GN38Jz14P777Us899MEqOCwbJOzvOxl3B/4nUiSupTr4YRn+0x8uKNAjMbBrwEyAXuMvdb057/IvAj4CN4ab/cfe7oqwp2TVUlB4EyeUlCodAv9KDC4Ihx8KJ58PrPw++hZx4fuf7tzTA3Cug7i8HPzDWsD0Yj7jozn3b3nowGLQuHAzWwUBs1AYc3f4/9LSbg7/Pc74NffL3bT/zX6C6ClaGXWmWA9P+X/D3KPEw6Uuw/g/B2NywsT3//Dm5MONWeOxvgxZpJnlr8AFfOAQmXN7xPs/PgYV3QVFJx4+PnHRkBYGZ5QK3AecC1cBCM5vn7svSdn3Y3a+Jqo509WHXUHH6GEGyRVA4KOjSqDuIrqFhJwZvUv5AWFm5/yD444+h9j34wpNQcWb3Xivp998LBtsmfh4qPgZ7tgezdUZ9BL70LOQcJj1/g0bBl/+v/fb8YvhSZe/XI4ePnFy49P5oX+PoU+Grb0b7Gl3R1gb3fAp+9+9wwvT2YyGbFkPV3TD1K3Dej3q1tCg/KaYCa9x9nbs3A3OBmRG+XpfsaxF0MkZQMKj7LYLWFtixPhhfyM2DMZ+EVfODN74j29bCy/8NJ19y8CEAcMbXYdAx+wZjf//d4DjO/8/DJwREJJCTE/zf3LMt+BKXqq0tmGRRNBQ+8c3eLy3C5x4JbEi5Xx1uS3eRmb1tZo+Z2aiOnsjMZptZlZlV1dQc2jpA9U0J+vbJIS837dAbU1sEpd1beG7He9CW2Dfj6ITzgiDZuKj9vu5Q+c9Bn/invtf+8e7oWwTTfwQ1K4L511W/gI/8PRx18qE9r4hEY8R4mPKVoPtnU0or5Y37gs+LT32v52ZNdUOmvzY+CZS7+ynA74D7OtrJ3e9w98nuPrm0tLSjXbqs03WGGmqDvvrcvKBrqL6m61POklNHkzOOjj8nGPxa+XT7fZfPg7XPw9nfhP5HHdxBpDphWhA87zwSnIhz1g2H/pwiEp2zvxl82Xz8H4IxgefnwPPfgdFnwCmXZqSkKINgI5D6Db+MfYPCALj7NndvCu/eBaSdb97z6ju7cH1jbdAtBFA8DBINwcyfrti2JvhZclzws3BwMHNm0b1Qv23ffk118Mz1MPzk4FtBT5l2M5SeCBf8GAoG9NzzikjPKxgY/F/dWR3MEHr5J9CnMJpZU10U5ayhhcAYM6sgCIDLgCtSdzCzEe7+fnh3BrA8wnqA5LUIOlmCOtkk6xe2Ouq3BAOaB7J1dTDKnzqN89w58POPwXPfhpn/E2x78YewexNceh/k9uBf/eDRwVm4InJkGPvXwZ/DRGQtAndPANcA8wk+4B9x96VmNsfMZoS7fdXMlprZW8BXgS9GVU9Sp1cna0hpEewNgi6OE2xbs69bKGn4ODjtH4I5zBtehy3Lg/n9p14Jo6Ye/AGIiPSwSM8jcPdKoDJt240pt28AerVTu66plYGFee0faKzdN3+939DgZ1dnDm1dHZw4le7j18M7vw5mA+QPgPz+8Mk5B1e4iEhEYndm8Z6mBEcPLGj/QIddQylB8PajULc5uJ3TB06+FPqVBGsU1W9p3yKAoFtp2g+C5RUALvjv4HdERA4jsQuC+qbudA2FQbB5Cfzm7z64/8pn4PNPwNZwoLiz1Q3HzQyWW2ishYlfOPQDEBHpYbELgrqmDqaPJpqCWULJFkGf/ODs4OTZxclF5L66OOg2evMBePZfYcmvg9U2oeMWAQSzAC65d99tEZHDTKbPI+hV7s6e5laK0q9Otnd5icH7tiXPJQBY9QyMnAxDKoJ+/qlfgRETYP43YdMbwZo+g8s7f2EzhYCIHLZiFQRNiTYSbd6+ayh1eYmk5DITuzcHZ/ydMH3fYzm5cP6PgwXjXr8zmL7Zp2/0ByAiEoFYBUF9Z0tQpy4vkdRvaDB9NHmRmdQggOBaq5O+GKwo2Fm3kIjIESBWQZC8KE2nXUMFqV1DYYtg5bPBwm7DxrV/wnNuDK7EVTY5oopFRKIXq8HiTi9K01GLoHhYsErguheCb/4d9fEXDQkGkFPX2BcROcLEKgjqO7twfXKMoDCtRYBDohE+NK3zJ83r4JwEEZEjSKy6huo7vV5xsmto4L5tybOL8wcE11IVEclS8QqCZIugjwcniSU11gYf+DkpAZE8qez4T2pGkIhktVgFQXKMoPS9Srj9dNiyInigobb9xSAGlwfnB5z02d4tUkSkl8VqjGBPGASFe8LLIqx8OrjOcMOOD55DADCwDK5bta+LSEQkS8WqRZAcI+jbFF4sJrl0RGMHLQJQCIhILMQqCOqaEuTlGn0awiCoroK6LR9ccE5EJGZiFQR7mhIU9e0TnChWOBhwWDU/XIJ68AF/X0QkG8UqCOqaWoOTyeq3BlNCB5QF3UOddQ2JiMRArIIguBZBbtAd1K8UTpgGa56D1mZ1DYlIbMUrCJoTFOdZsHRE8bBgIbnWpuBBtQhEJKYinT5qZtOAnwC5wF3ufnMn+10EPAZMcfeqqOqpb0pwVN4ewIMWQfnHoG8xNNepRSCS5VpaWqiurqaxsTHTpUSqoKCAsrIy8vI6uDZ7JyILAjPLBW4DzgWqgYVmNs/dl6Xt1x+4FngtqlqS6ptaGd5/d3Cn39Bgsbjjzobl8zRYLJLlqqur6d+/P+Xl5ViWXijK3dm2bRvV1dVUVFR0+fei7BqaCqxx93Xu3gzMBWZ2sN93gR8Ckcd0fXOC0pxkEIRLSIz96+Bn/xFRv7yIZFBjYyMlJSVZGwIAZkZJSUm3Wz1RBsFIYEPK/epw215mNhEY5e5PR1jHXvVNCYbazuBOMghOvgS+8vvgDGMRyWrZHAJJB3OMGRssNrMc4MfAN7qw72wzqzKzqpqamoN+zfrmVoaQFgRmMHLSQT+niMiRLsog2AiMSrlfFm5L6g+cBCwws3eB04B5Ztbucl/ufoe7T3b3yaWlpQdVTEtrG82JNga21UJOHw0Oi0ivqq2t5Wc/+1m3f++8886jtrY2gor2iTIIFgJjzKzCzPoClwHzkg+6+053H+ru5e5eDrwKzIhq1lByCeoBrbVQNBRyYjVzVkQyrLMgSCQS+/29yspKBg2K9otrZLOG3D1hZtcA8wmmj97j7kvNbA5Q5e7z9v8MPSu54Fxxa+2+biERiaXvPLmUZZt29ehzjjt6AN/+6w93+vj111/P2rVrmTBhAnl5eRQUFDB48GBWrFjBqlWruPDCC9mwYQONjY1ce+21zJ49G4Dy8nKqqqqoq6tj+vTpnHHGGbzyyiuMHDmSJ554gsLCwkOuPdLzCNy9EqhM23ZjJ/ueFWUtyRZBUfM2GKxVRUWkd918880sWbKExYsXs2DBAs4//3yWLFmyd5rnPffcw5AhQ2hoaGDKlClcdNFFlJSUfOA5Vq9ezUMPPcSdd97JpZdeyq9//WuuvPLKQ64tNtcjSF6UpqB5O/TTDCGRONvfN/feMnXq1A/M9b/11lt5/PHHAdiwYQOrV69uFwQVFRVMmDABgEmTJvHuu+/2SC2xCYI9TclrEWxX15CIZFy/fv323l6wYAHPPfccf/rTnygqKuKss87q8FyA/Pz8vbdzc3NpaGjokVpiM2Ja15SgkEZyE3ugWEEgIr2rf//+7N69u8PHdu7cyeDBgykqKmLFihW8+uqrvVpbbFoE9U0JSiztrGIRkV5SUlLC6aefzkknnURhYSHDhw/f+9i0adO4/fbbGTt2LCeccAKnnXZar9YWmyDY05xgaPrJZCIivejBBx/scHt+fj7PPPNMh48lxwGGDh3KkiVL9m6/7rrreqyuGHUNtVKyd3kJzRoSEUmKTYvgiqnH8FmOggWoRSAikiI2QTCwKI+BuRojEBFJF5uuISC4VnHf/pB36GfiiYhki5gFQY3GB0RE0sQrCJIXrRcRkb3iFQT1WxUEInJYuOmmm7jlllsyXQYQuyBQ15CISLrYzBqirQ32qEUgIsAz18Pmd3r2OY86GabfvN9dvv/973PfffcxbNgwRo0axaRJk1i7di1XX301NTU1FBUVceeddzJixAhOOeUU1q9fT05ODvX19Zx44omsW7eOvLy8nq2bOLUIGnaAt0HxsExXIiIxtGjRIubOncvixYuprKxk4cKFAMyePZuf/vSnLFq0iFtuuYWrrrqKgQMHMmHCBF588UUAnnrqKT796U9HEgIQpxZB/Zbgp7qGROQA39yj8Mc//pHPfOYzFBUVATBjxgwaGxt55ZVXuOSSS/bu19TUBMCsWbN4+OGH+cQnPsHcuXO56qqrIqstRkEQXvReXUMicphoa2tj0KBBLF68uN1jM2bM4N/+7d/Yvn07ixYt4uyzz46sjvh0DSkIRCSDzjzzTH7729/S0NDA7t27efLJJykqKqKiooJHH30UAHfnrbfeAqC4uJgpU6Zw7bXXcsEFF5CbmxtZbTEKgq3BTwWBiGTAxIkTmTVrFuPHj2f69OlMmTIFgAceeIC7776b8ePH8+EPf5gnnnhi7+/MmjWLX/3qV8yaNSvS2szdI32BnjZ58mSvqqrq/i+ueBoWPwiX3g850SWriByeli9fztixYzNdRq/o6FjNbJG7T+5o/0hbBGY2zcxWmtkaM7u+g8f/3szeMbPFZvaSmY2LrJgTz4fLHlAIiIikiSwIzCwXuA2YDowDLu/gg/5Bdz/Z3ScA/wH8OKp6RESkY1G2CKYCa9x9nbs3A3OBmak7uPuulLv9gCOrn0pEjihHWlf4wTiYY4wyCEYCG1LuV4fbPsDMrjaztQQtgq929ERmNtvMqsysqqamJpJiRSS7FRQUsG3btqwOA3dn27ZtFBQUdOv3Mn4egbvfBtxmZlcA3wK+0ME+dwB3QDBY3LsVikg2KCsro7q6mmz/MllQUEBZWVm3fifKINgIjEq5XxZu68xc4H8jrEdEYiwvL4+KiopMl3FYirJraCEwxswqzKwvcBkwL3UHMxuTcvd8YHWE9YiISAciaxG4e8LMrgHmA7nAPe6+1MzmAFXuPg+4xsw+CbQAO+igW0hERKIV6RiBu1cClWnbbky5fW2Ury8iIgd2xJ1ZbGY1wHsH+etDga09WM6RIo7HHcdjhngedxyPGbp/3KPdvcM1do64IDgUZlbV2SnW2SyOxx3HY4Z4Hnccjxl69rjjs+iciIh0SEEgIhJzcQuCOzJdQIbE8bjjeMwQz+OO4zFDD8FxLYMAAATzSURBVB53rMYIRESkvbi1CEREJI2CQEQk5mITBAe6SE42MLNRZvaCmS0zs6Vmdm24fYiZ/c7MVoc/B2e61p5mZrlm9qaZPRXerzCz18L3++FwmZOsYmaDzOwxM1thZsvN7K9i8l7/U/jve4mZPWRmBdn2fpvZPWa2xcyWpGzr8L21wK3hsb9tZhO7+3qxCIIuXiQnGySAb7j7OOA04OrwOK8Hnnf3McDz4f1scy2wPOX+D4H/cvfjCZYv+XJGqorWT4Bn3f1EYDzB8Wf1e21mIwmWq5/s7icRLF9zGdn3ft8LTEvb1tl7Ox0YE/6ZzUEs3hmLIKALF8nJBu7+vru/Ed7eTfDBMJLgWO8Ld7sPuDAzFUbDzMoIFi28K7xvwNnAY+Eu2XjMA4EzgbsB3L3Z3WvJ8vc61AcoNLM+QBHwPln2frv7H4DtaZs7e29nAvd74FVgkJmN6M7rxSUIunSRnGxiZuXAqcBrwHB3fz98aDMwPENlReW/gX8B2sL7JUCtuyfC+9n4flcANcAvwi6xu8ysH1n+Xrv7RuAW4M8EAbATWET2v9/Q+Xt7yJ9vcQmCWDGzYuDXwNfSLgeKB/OFs2bOsJldAGxx90WZrqWX9QEmAv/r7qcC9aR1A2Xbew0Q9ovPJAjCowkucZvehZL1evq9jUsQdPciOUcsM8sjCIEH3P034ea/JJuK4c8tmaovAqcDM8zsXYIuv7MJ+s4HhV0HkJ3vdzVQ7e6vhfcfIwiGbH6vAT4JrHf3GndvAX5D8G8g299v6Py9PeTPt7gEwQEvkpMNwr7xu4Hl7v7jlIfmse9aD18Anujt2qLi7je4e5m7lxO8r793978BXgAuDnfLqmMGcPfNwAYzOyHcdA6wjCx+r0N/Bk4zs6Lw33vyuLP6/Q519t7OAz4fzh46DdiZ0oXUNe4eiz/AecAqYC3wzUzXE9ExnkHQXHwbWBz+OY+gz/x5givAPQcMyXStER3/WcBT4e1jgdeBNcCjQH6m64vgeCcAVeH7/VtgcBzea+A7wApgCfBLID/b3m/gIYIxkBaC1t+XO3tvASOYFbkWeIdgRlW3Xk9LTIiIxFxcuoZERKQTCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQ6UVmdlZyhVSRw4WCQEQk5hQEIh0wsyvN7HUzW2xmPw+vd1BnZv8VroX/vJmVhvtOMLNXw7XgH09ZJ/54M3vOzN4yszfM7Ljw6YtTriPwQHiGrEjGKAhE0pjZWGAWcLq7TwBagb8hWOCsyt0/DLwIfDv8lfuBf3X3UwjO7ExufwC4zd3HAx8lOFMUglVhv0ZwbYxjCdbKEcmYPgfeRSR2zgEmAQvDL+uFBAt8tQEPh/v8CvhNeF2AQe7+Yrj9PuBRM+sPjHT3xwHcvREgfL7X3b06vL8YKAdeiv6wRDqmIBBpz4D73P2GD2w0+/e0/Q52fZamlNut6P+hZJi6hkTaex642MyGwd5rxY4m+P+SXOHyCuAld98J7DCzj4XbPwe86MEV4qrN7MLwOfLNrKhXj0Kki/RNRCSNuy8zs28B/2dmOQQrQF5NcPGXqeFjWwjGESBYEvj28IN+HfClcPvngJ+b2ZzwOS7pxcMQ6TKtPirSRWZW5+7Fma5DpKepa0hEJObUIhARiTm1CEREYk5BICIScwoCEZGYUxCIiMScgkBEJOb+PylTnDyM5V4kAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(epoch, dev_loss_history, label='loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('%')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "syO1UqbKqgHc",
        "outputId": "b9815833-27e4-4451-d55c-0f9f41e60d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKx6lu5NhvHI",
        "outputId": "d2af3183-702f-4c51-8c2d-698866f8dcc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "{'doc_id': '23352901', 'sent_id': 1, 'sentence': \"Đây là lý do khiến Yoon Ah quyết định cắt mái tóc dài 'nữ thần' Mái tóc cũ của thành viên SNSD bị hư hỏng nặng nề và Yoon Ah thậm chí không muốn nuôi tóc lại.\", 'spos': [0, 158], 'entity_1': {'text': 'Yoon Ah', 'pos': [19, 26]}, 'entity_2': {'text': 'SNSD', 'pos': [90, 94]}, 'entity_1_info': {'first_token': [5, 6, 1, 'PERSON'], 'last_token': [6, 7, 1, 'PERSON']}, 'entity_2_info': {'first_token': [21, 22, 0, 'ORGANIZATION'], 'last_token': [21, 22, 0, 'ORGANIZATION']}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23352901', 'sent_id': 2, 'sentence': \"Đây là lý do khiến Yoon Ah quyết định cắt mái tóc dài 'nữ thần' Mái tóc cũ của thành viên SNSD bị hư hỏng nặng nề và Yoon Ah thậm chí không muốn nuôi tóc lại.\", 'spos': [0, 158], 'entity_1': {'text': 'Yoon Ah', 'pos': [19, 26]}, 'entity_2': {'text': 'Yoon Ah', 'pos': [117, 124]}, 'entity_1_info': {'first_token': [5, 6, 1, 'PERSON'], 'last_token': [6, 7, 1, 'PERSON']}, 'entity_2_info': {'first_token': [28, 29, 2, 'PERSON'], 'last_token': [29, 30, 2, 'PERSON']}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23352901', 'sent_id': 3, 'sentence': \"Đây là lý do khiến Yoon Ah quyết định cắt mái tóc dài 'nữ thần' Mái tóc cũ của thành viên SNSD bị hư hỏng nặng nề và Yoon Ah thậm chí không muốn nuôi tóc lại.\", 'spos': [0, 158], 'entity_1': {'text': 'SNSD', 'pos': [90, 94]}, 'entity_2': {'text': 'Yoon Ah', 'pos': [117, 124]}, 'entity_1_info': {'first_token': [21, 22, 0, 'ORGANIZATION'], 'last_token': [21, 22, 0, 'ORGANIZATION']}, 'entity_2_info': {'first_token': [28, 29, 2, 'PERSON'], 'last_token': [29, 30, 2, 'PERSON']}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23352901', 'sent_id': 4, 'sentence': 'Soo Young và Seo Hyun cắt để đóng phim, Yoon Ah và Sunny muốn thay đổi bản thân và Yuri cũng mới tỉa thành kiểu tóc ngang vai trẻ trung.', 'spos': [1128, 1264], 'entity_1': {'text': 'Soo Young', 'pos': [0, 9]}, 'entity_2': {'text': 'Seo Hyun', 'pos': [13, 21]}, 'entity_1_info': {'first_token': [258, 259, 8, 'PERSON'], 'last_token': [259, 260, 8, 'PERSON']}, 'entity_2_info': {'first_token': [261, 262, 9, 'PERSON'], 'last_token': [262, 263, 9, 'PERSON']}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23352901', 'sent_id': 5, 'sentence': 'Soo Young và Seo Hyun cắt để đóng phim, Yoon Ah và Sunny muốn thay đổi bản thân và Yuri cũng mới tỉa thành kiểu tóc ngang vai trẻ trung.', 'spos': [1128, 1264], 'entity_1': {'text': 'Soo Young', 'pos': [0, 9]}, 'entity_2': {'text': 'Yoon Ah', 'pos': [40, 47]}, 'entity_1_info': {'first_token': [258, 259, 8, 'PERSON'], 'last_token': [259, 260, 8, 'PERSON']}, 'entity_2_info': {'first_token': [267, 268, 10, 'PERSON'], 'last_token': [268, 269, 10, 'PERSON']}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23352901', 'sent_id': 6, 'sentence': 'Soo Young và Seo Hyun cắt để đóng phim, Yoon Ah và Sunny muốn thay đổi bản thân và Yuri cũng mới tỉa thành kiểu tóc ngang vai trẻ trung.', 'spos': [1128, 1264], 'entity_1': {'text': 'Soo Young', 'pos': [0, 9]}, 'entity_2': {'text': 'Sunny', 'pos': [51, 56]}, 'entity_1_info': {'first_token': [258, 259, 8, 'PERSON'], 'last_token': [259, 260, 8, 'PERSON']}, 'entity_2_info': {'first_token': [270, 271, 0, 'PERSON'], 'last_token': [270, 271, 0, 'PERSON']}, 'label': 'OTHERS'}\n"
          ]
        }
      ],
      "source": [
        "with open('test_data.json') as test_data_json:\n",
        "  jtest_data = json.load(test_data_json)\n",
        "\n",
        "print(type(jtest_data))\n",
        "print(*jtest_data[0:6], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwllvbLJiN_b"
      },
      "outputs": [],
      "source": [
        "jtest_data_v1 = copy.deepcopy(add_word_tokenize_and_entity_index(jtest_data, 'test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxcUsSndiYcC",
        "outputId": "94fea841-9fa4-4b9e-b7a6-9d33e51a40ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "['Đây', 'là', 'lý_do', 'khiến', 'Yoon_@@', 'Ah', 'quyết_định', 'cắt', 'mái_tóc', 'dài', \"'\", 'nữ', 'thần', \"'\", 'Mái_tóc', 'cũ', 'của', 'thành_viên', 'SNSD', 'bị', 'hư_hỏng', 'nặng_nề', 'và', 'Yoon_@@', 'Ah', 'thậm_chí', 'không', 'muốn', 'nuôi', 'tóc', 'lại', '.']\n",
            "Yoon Ah\n",
            "[5, 6, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "SNSD\n",
            "[19, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Đây', 'là', 'lý_do', 'khiến', 'Yoon_@@', 'Ah', 'quyết_định', 'cắt', 'mái_tóc', 'dài', \"'\", 'nữ', 'thần', \"'\", 'Mái_tóc', 'cũ', 'của', 'thành_viên', 'SNSD', 'bị', 'hư_hỏng', 'nặng_nề', 'và', 'Yoon_@@', 'Ah', 'thậm_chí', 'không', 'muốn', 'nuôi', 'tóc', 'lại', '.']\n",
            "Yoon Ah\n",
            "[5, 6, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Yoon Ah\n",
            "[24, 25, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Đây', 'là', 'lý_do', 'khiến', 'Yoon_@@', 'Ah', 'quyết_định', 'cắt', 'mái_tóc', 'dài', \"'\", 'nữ', 'thần', \"'\", 'Mái_tóc', 'cũ', 'của', 'thành_viên', 'SNSD', 'bị', 'hư_hỏng', 'nặng_nề', 'và', 'Yoon_@@', 'Ah', 'thậm_chí', 'không', 'muốn', 'nuôi', 'tóc', 'lại', '.']\n",
            "SNSD\n",
            "[19, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Yoon Ah\n",
            "[24, 25, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Soo_@@', 'Young', 'và', 'Seo_@@', 'Hyun', 'cắt', 'để', 'đóng_@@', 'phim', ',', 'Yoon_@@', 'Ah', 'và', 'Sunny', 'muốn', 'thay_đổi', 'bản_thân', 'và', 'Yuri', 'cũng', 'mới', 'tỉa', 'thành', 'kiểu', 'tóc', 'ngang_@@', 'vai', 'trẻ_trung', '.']\n",
            "Soo Young\n",
            "[1, 2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Seo Hyun\n",
            "[4, 5, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Soo_@@', 'Young', 'và', 'Seo_@@', 'Hyun', 'cắt', 'để', 'đóng_@@', 'phim', ',', 'Yoon_@@', 'Ah', 'và', 'Sunny', 'muốn', 'thay_đổi', 'bản_thân', 'và', 'Yuri', 'cũng', 'mới', 'tỉa', 'thành', 'kiểu', 'tóc', 'ngang_@@', 'vai', 'trẻ_trung', '.']\n",
            "Soo Young\n",
            "[1, 2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Yoon Ah\n",
            "[11, 12, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Soo_@@', 'Young', 'và', 'Seo_@@', 'Hyun', 'cắt', 'để', 'đóng_@@', 'phim', ',', 'Yoon_@@', 'Ah', 'và', 'Sunny', 'muốn', 'thay_đổi', 'bản_thân', 'và', 'Yuri', 'cũng', 'mới', 'tỉa', 'thành', 'kiểu', 'tóc', 'ngang_@@', 'vai', 'trẻ_trung', '.']\n",
            "Soo Young\n",
            "[1, 2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Sunny\n",
            "[14, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Soo_@@', 'Young', 'và', 'Seo_@@', 'Hyun', 'cắt', 'để', 'đóng_@@', 'phim', ',', 'Yoon_@@', 'Ah', 'và', 'Sunny', 'muốn', 'thay_đổi', 'bản_thân', 'và', 'Yuri', 'cũng', 'mới', 'tỉa', 'thành', 'kiểu', 'tóc', 'ngang_@@', 'vai', 'trẻ_trung', '.']\n",
            "Seo Hyun\n",
            "[4, 5, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Yoon Ah\n",
            "[11, 12, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Soo_@@', 'Young', 'và', 'Seo_@@', 'Hyun', 'cắt', 'để', 'đóng_@@', 'phim', ',', 'Yoon_@@', 'Ah', 'và', 'Sunny', 'muốn', 'thay_đổi', 'bản_thân', 'và', 'Yuri', 'cũng', 'mới', 'tỉa', 'thành', 'kiểu', 'tóc', 'ngang_@@', 'vai', 'trẻ_trung', '.']\n",
            "Seo Hyun\n",
            "[4, 5, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Sunny\n",
            "[14, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Soo_@@', 'Young', 'và', 'Seo_@@', 'Hyun', 'cắt', 'để', 'đóng_@@', 'phim', ',', 'Yoon_@@', 'Ah', 'và', 'Sunny', 'muốn', 'thay_đổi', 'bản_thân', 'và', 'Yuri', 'cũng', 'mới', 'tỉa', 'thành', 'kiểu', 'tóc', 'ngang_@@', 'vai', 'trẻ_trung', '.']\n",
            "Yoon Ah\n",
            "[11, 12, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Sunny\n",
            "[14, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Bày_tỏ', 'quan_điểm', 'cũng', 'b@@', 'ực_t@@', 'ức_@@', 'như', 'Tu_@@', 'Dinh_@@', 'Hu@@', 'ong', ',', 'thành_viên', 'Py@@', 'mini', 'tiếp_lời', ':', '\"', 'Nhà', 'mình', 'mà', 'phần', 'cho', 'người', 'sau', 'thì', 'còn', 'chọn', 'toàn', 'cái', 'ngon', 'để_phần', ',', 'chứ', 'không', 'có', 'chuyện', 'ăn_uống', 'bày', 'bừa', ',', 'mặc_kệ', 'người', 'ăn', 'sau', 'như', 'thế_này', '”', '.']\n",
            "Tu Dinh Huong\n",
            "[8, 9, 10, 11, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Pymini\n",
            "[14, 15, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n"
          ]
        }
      ],
      "source": [
        "test_pb_input_ids=[]\n",
        "test_pb_attention_masks=[]\n",
        "test_pb_entity_1_eids = []\n",
        "test_pb_entity_2_eids=[]\n",
        "test_labels = []\n",
        "\n",
        "pad_ent_eid = -2\n",
        "max_len_ent_eid = 30\n",
        "\n",
        "\n",
        "jtest_data_use = copy.deepcopy(jtest_data_v1)\n",
        "\n",
        "for isentif, sentif in enumerate(jtest_data_use):\n",
        "    \n",
        "    pb_base_input_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n",
        "\n",
        "    pb_base_encode_dict = pb_tokenizer(pb_base_input_sent, add_special_tokens=True, padding='max_length', max_length=192)\n",
        "\n",
        "    pb_base_tokenize_lst = pb_tokenizer.tokenize(pb_base_input_sent)\n",
        "  \n",
        "    pb_base_entity_1_eids = get_entity_word_piece_index(pb_base_tokenize_lst, sentif['entity_1'], sentif['sentence'], pb_base_encode_dict['input_ids'], 'test')\n",
        "    pb_base_entity_2_eids = get_entity_word_piece_index(pb_base_tokenize_lst, sentif['entity_2'], sentif['sentence'], pb_base_encode_dict['input_ids'], 'test')\n",
        "\n",
        "    # pad\n",
        "   \n",
        "    pb_base_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_base_entity_1_eids))\n",
        "    pb_base_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_base_entity_2_eids))\n",
        "      \n",
        "\n",
        "\n",
        "    if isentif < 10:\n",
        "        print('\\n')\n",
        "        print(pb_base_tokenize_lst)\n",
        "        print(sentif['entity_1']['text'])\n",
        "        print(pb_base_entity_1_eids)\n",
        "        print(sentif['entity_2']['text'])\n",
        "        print(pb_base_entity_2_eids)\n",
        "      \n",
        "\n",
        "\n",
        "    test_pb_input_ids.append(copy.deepcopy(pb_base_encode_dict['input_ids']))\n",
        "    test_pb_attention_masks.append(copy.deepcopy(pb_base_encode_dict['attention_mask']))\n",
        "    test_pb_entity_1_eids.append(copy.deepcopy(pb_base_entity_1_eids))\n",
        "    test_pb_entity_2_eids.append(copy.deepcopy(pb_base_entity_2_eids))\n",
        "    test_labels.append(copy.deepcopy(encode_label(sentif['label'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPP7VXFyj5UZ"
      },
      "outputs": [],
      "source": [
        "test_pb_input_ids = torch.tensor(test_pb_input_ids)\n",
        "test_pb_attention_masks = torch.tensor(test_pb_attention_masks)\n",
        "test_pb_entity_1_eids = torch.tensor(test_pb_entity_1_eids)\n",
        "test_pb_entity_2_eids = torch.tensor(test_pb_entity_2_eids)\n",
        "test_labels = torch.tensor(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEPRn6kejvEA"
      },
      "outputs": [],
      "source": [
        "test_dataset = TensorDataset(test_pb_input_ids, test_pb_attention_masks, test_pb_entity_1_eids, test_pb_entity_2_eids,test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNa5JJFJlVSn"
      },
      "outputs": [],
      "source": [
        "model_1_path = 'rec_model_save/rec_model.bin'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVZg1IyQlpvB",
        "outputId": "f1b0a621-2331-4e35-cc23-b22c102504aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "re_model_1 = REClassifier(flags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG-Yf-o6lqLL",
        "outputId": "890067ca-77b0-4cf2-c3e6-8c4a44c3e6fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "re_model_1.load_state_dict(torch.load(model_1_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxDQ6XnOluqF"
      },
      "outputs": [],
      "source": [
        "def decode_label(sentence_label):\n",
        "    label = -1\n",
        "    if sentence_label == 0:\n",
        "        label = \"LOCATED\"\n",
        "    elif sentence_label == 1:\n",
        "        label = \"PART_WHOLE\"\n",
        "    elif sentence_label == 2:\n",
        "        label = \"PERSONAL_SOCIAL\"\n",
        "    elif sentence_label == 3:\n",
        "        label = \"AFFILIATION\"\n",
        "    elif sentence_label == 4:\n",
        "        label = \"OTHERS\"\n",
        "    \n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7DRaBEm4W5P",
        "outputId": "c21d7748-21dd-4d24-a323-32f042117fa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ],
      "source": [
        "# GPU\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hby_rkwAlvct",
        "outputId": "b54cd8aa-0e68-4c87-bc9f-2fcba3360a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "re_model_1.to(device)\n",
        "\n",
        "re_model_1.eval()\n",
        "\n",
        "model_1_outputs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        sampler = torch.utils.data.SequentialSampler(test_dataset),\n",
        "        batch_size=flags['batch_size'])\n",
        "    \n",
        "    for batch_num, batch in enumerate(test_loader):\n",
        "        if batch_num % 30 == 0:\n",
        "            print(batch_num)\n",
        "            \n",
        "        pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, targets = \\\n",
        "        batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), \\\n",
        "        batch[4].to(device)\n",
        "\n",
        "            \n",
        "        # Acquires the network's best guesses at each class\n",
        "        output = re_model_1(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids)\n",
        "\n",
        "            \n",
        "        labels = torch.argmax(output, dim=1)\n",
        "\n",
        "        labels_decoded = [decode_label(label) for label in labels]\n",
        "\n",
        "        model_1_outputs.extend(copy.deepcopy(labels_decoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nIOXMgwK27j"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEPiEdlfmNWN"
      },
      "outputs": [],
      "source": [
        "model_1_results = copy.deepcopy(jtest_data_v1)\n",
        "\n",
        "for i in range(len(jtest_data_v1)):\n",
        "    model_1_results[i]['label'] = copy.deepcopy(model_1_outputs[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut5z-X_Dk8_M"
      },
      "outputs": [],
      "source": [
        "label=[]\n",
        "for i in jtest_data:\n",
        "  label.append(i[\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bAyhRlCmYWE",
        "outputId": "1d700678-e0fa-4f8d-da6d-919f77e77a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'doc_id': '23352901', 'sent_id': 4, 'sentence': 'Soo Young và Seo Hyun cắt để đóng phim, Yoon Ah và Sunny muốn thay đổi bản thân và Yuri cũng mới tỉa thành kiểu tóc ngang vai trẻ trung.', 'spos': [1128, 1264], 'entity_1': {'text': 'Soo Young', 'pos': [0, 9], 'pos_no_space': [0, 8]}, 'entity_2': {'text': 'Seo Hyun', 'pos': [13, 21], 'pos_no_space': [10, 17]}, 'entity_1_info': {'first_token': [258, 259, 8, 'PERSON'], 'last_token': [259, 260, 8, 'PERSON']}, 'entity_2_info': {'first_token': [261, 262, 9, 'PERSON'], 'last_token': [262, 263, 9, 'PERSON']}, 'label': 'AFFILIATION', 'word_tokenize_lst': ['Soo Young', 'và', 'Seo Hyun', 'cắt', 'để', 'đóng phim', ',', 'Yoon Ah', 'và', 'Sunny', 'muốn', 'thay đổi', 'bản thân', 'và', 'Yuri', 'cũng', 'mới', 'tỉa', 'thành', 'kiểu', 'tóc', 'ngang vai', 'trẻ trung', '.']}\n",
            "{'doc_id': '23352332', 'sent_id': 24, 'sentence': 'Chiều 22-9, tại Lai Châu, Thiếu tướng Đỗ Danh Vượng, Chính ủy BĐBP, Chủ tịch Hội đồng thi đua, khen thưởng BĐBP chủ trì Hội nghị Tổng kết công tác thi đua, khen thưởng và phong trào Thi đua Quyết thắng năm 2017 của Cụm Thi đua số 1 BĐBP (gồm 8 tỉnh biên giới phía Bắc: Quảng Ninh, Lạng Sơn, Cao Bằng, Hà Giang, Lào Cai, Lai Châu, Điện Biên và Sơn La).', 'spos': [90, 440], 'entity_1': {'text': 'Quảng Ninh', 'pos': [269, 279], 'pos_no_space': [212, 221]}, 'entity_2': {'text': 'Lạng Sơn', 'pos': [281, 289], 'pos_no_space': [222, 229]}, 'label': 'PART_WHOLE', 'word_tokenize_lst': ['Chiều', '22-9', ',', 'tại', 'Lai Châu', ',', 'Thiếu tướng', 'Đỗ Danh Vượng', ',', 'Chính ủy BĐBP', ',', 'Chủ tịch', 'Hội đồng', 'thi đua', ',', 'khen thưởng', 'BĐBP', 'chủ trì', 'Hội nghị', 'Tổng kết', 'công tác', 'thi đua', ',', 'khen thưởng', 'và', 'phong trào', 'Thi đua', 'Quyết thắng', 'năm', '2017', 'của', 'Cụm', 'Thi đua', 'số', '1', 'BĐBP', '(', 'gồm', '8', 'tỉnh', 'biên giới', 'phía', 'Bắc', ':', 'Quảng Ninh', ',', 'Lạng Sơn', ',', 'Cao Bằng', ',', 'Hà Giang', ',', 'Lào Cai', ',', 'Lai Châu', ',', 'Điện Biên', 'và', 'Sơn La', ')', '.']}\n",
            "{'doc_id': '23352332', 'sent_id': 25, 'sentence': 'Chiều 22-9, tại Lai Châu, Thiếu tướng Đỗ Danh Vượng, Chính ủy BĐBP, Chủ tịch Hội đồng thi đua, khen thưởng BĐBP chủ trì Hội nghị Tổng kết công tác thi đua, khen thưởng và phong trào Thi đua Quyết thắng năm 2017 của Cụm Thi đua số 1 BĐBP (gồm 8 tỉnh biên giới phía Bắc: Quảng Ninh, Lạng Sơn, Cao Bằng, Hà Giang, Lào Cai, Lai Châu, Điện Biên và Sơn La).', 'spos': [90, 440], 'entity_1': {'text': 'Quảng Ninh', 'pos': [269, 279], 'pos_no_space': [212, 221]}, 'entity_2': {'text': 'Cao Bằng', 'pos': [291, 299], 'pos_no_space': [230, 237]}, 'label': 'PART_WHOLE', 'word_tokenize_lst': ['Chiều', '22-9', ',', 'tại', 'Lai Châu', ',', 'Thiếu tướng', 'Đỗ Danh Vượng', ',', 'Chính ủy BĐBP', ',', 'Chủ tịch', 'Hội đồng', 'thi đua', ',', 'khen thưởng', 'BĐBP', 'chủ trì', 'Hội nghị', 'Tổng kết', 'công tác', 'thi đua', ',', 'khen thưởng', 'và', 'phong trào', 'Thi đua', 'Quyết thắng', 'năm', '2017', 'của', 'Cụm', 'Thi đua', 'số', '1', 'BĐBP', '(', 'gồm', '8', 'tỉnh', 'biên giới', 'phía', 'Bắc', ':', 'Quảng Ninh', ',', 'Lạng Sơn', ',', 'Cao Bằng', ',', 'Hà Giang', ',', 'Lào Cai', ',', 'Lai Châu', ',', 'Điện Biên', 'và', 'Sơn La', ')', '.']}\n",
            "{'doc_id': '23352332', 'sent_id': 26, 'sentence': 'Chiều 22-9, tại Lai Châu, Thiếu tướng Đỗ Danh Vượng, Chính ủy BĐBP, Chủ tịch Hội đồng thi đua, khen thưởng BĐBP chủ trì Hội nghị Tổng kết công tác thi đua, khen thưởng và phong trào Thi đua Quyết thắng năm 2017 của Cụm Thi đua số 1 BĐBP (gồm 8 tỉnh biên giới phía Bắc: Quảng Ninh, Lạng Sơn, Cao Bằng, Hà Giang, Lào Cai, Lai Châu, Điện Biên và Sơn La).', 'spos': [90, 440], 'entity_1': {'text': 'Quảng Ninh', 'pos': [269, 279], 'pos_no_space': [212, 221]}, 'entity_2': {'text': 'Hà Giang', 'pos': [301, 309], 'pos_no_space': [238, 245]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Chiều', '22-9', ',', 'tại', 'Lai Châu', ',', 'Thiếu tướng', 'Đỗ Danh Vượng', ',', 'Chính ủy BĐBP', ',', 'Chủ tịch', 'Hội đồng', 'thi đua', ',', 'khen thưởng', 'BĐBP', 'chủ trì', 'Hội nghị', 'Tổng kết', 'công tác', 'thi đua', ',', 'khen thưởng', 'và', 'phong trào', 'Thi đua', 'Quyết thắng', 'năm', '2017', 'của', 'Cụm', 'Thi đua', 'số', '1', 'BĐBP', '(', 'gồm', '8', 'tỉnh', 'biên giới', 'phía', 'Bắc', ':', 'Quảng Ninh', ',', 'Lạng Sơn', ',', 'Cao Bằng', ',', 'Hà Giang', ',', 'Lào Cai', ',', 'Lai Châu', ',', 'Điện Biên', 'và', 'Sơn La', ')', '.']}\n",
            "{'doc_id': '23352332', 'sent_id': 27, 'sentence': 'Chiều 22-9, tại Lai Châu, Thiếu tướng Đỗ Danh Vượng, Chính ủy BĐBP, Chủ tịch Hội đồng thi đua, khen thưởng BĐBP chủ trì Hội nghị Tổng kết công tác thi đua, khen thưởng và phong trào Thi đua Quyết thắng năm 2017 của Cụm Thi đua số 1 BĐBP (gồm 8 tỉnh biên giới phía Bắc: Quảng Ninh, Lạng Sơn, Cao Bằng, Hà Giang, Lào Cai, Lai Châu, Điện Biên và Sơn La).', 'spos': [90, 440], 'entity_1': {'text': 'Quảng Ninh', 'pos': [269, 279], 'pos_no_space': [212, 221]}, 'entity_2': {'text': 'Lào Cai', 'pos': [311, 318], 'pos_no_space': [246, 252]}, 'label': 'PART_WHOLE', 'word_tokenize_lst': ['Chiều', '22-9', ',', 'tại', 'Lai Châu', ',', 'Thiếu tướng', 'Đỗ Danh Vượng', ',', 'Chính ủy BĐBP', ',', 'Chủ tịch', 'Hội đồng', 'thi đua', ',', 'khen thưởng', 'BĐBP', 'chủ trì', 'Hội nghị', 'Tổng kết', 'công tác', 'thi đua', ',', 'khen thưởng', 'và', 'phong trào', 'Thi đua', 'Quyết thắng', 'năm', '2017', 'của', 'Cụm', 'Thi đua', 'số', '1', 'BĐBP', '(', 'gồm', '8', 'tỉnh', 'biên giới', 'phía', 'Bắc', ':', 'Quảng Ninh', ',', 'Lạng Sơn', ',', 'Cao Bằng', ',', 'Hà Giang', ',', 'Lào Cai', ',', 'Lai Châu', ',', 'Điện Biên', 'và', 'Sơn La', ')', '.']}\n",
            "{'doc_id': '23352332', 'sent_id': 28, 'sentence': 'Chiều 22-9, tại Lai Châu, Thiếu tướng Đỗ Danh Vượng, Chính ủy BĐBP, Chủ tịch Hội đồng thi đua, khen thưởng BĐBP chủ trì Hội nghị Tổng kết công tác thi đua, khen thưởng và phong trào Thi đua Quyết thắng năm 2017 của Cụm Thi đua số 1 BĐBP (gồm 8 tỉnh biên giới phía Bắc: Quảng Ninh, Lạng Sơn, Cao Bằng, Hà Giang, Lào Cai, Lai Châu, Điện Biên và Sơn La).', 'spos': [90, 440], 'entity_1': {'text': 'Quảng Ninh', 'pos': [269, 279], 'pos_no_space': [212, 221]}, 'entity_2': {'text': 'Lai Châu', 'pos': [320, 328], 'pos_no_space': [253, 260]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Chiều', '22-9', ',', 'tại', 'Lai Châu', ',', 'Thiếu tướng', 'Đỗ Danh Vượng', ',', 'Chính ủy BĐBP', ',', 'Chủ tịch', 'Hội đồng', 'thi đua', ',', 'khen thưởng', 'BĐBP', 'chủ trì', 'Hội nghị', 'Tổng kết', 'công tác', 'thi đua', ',', 'khen thưởng', 'và', 'phong trào', 'Thi đua', 'Quyết thắng', 'năm', '2017', 'của', 'Cụm', 'Thi đua', 'số', '1', 'BĐBP', '(', 'gồm', '8', 'tỉnh', 'biên giới', 'phía', 'Bắc', ':', 'Quảng Ninh', ',', 'Lạng Sơn', ',', 'Cao Bằng', ',', 'Hà Giang', ',', 'Lào Cai', ',', 'Lai Châu', ',', 'Điện Biên', 'và', 'Sơn La', ')', '.']}\n",
            "{'doc_id': '23352345', 'sent_id': 32, 'sentence': 'Chiều 22-9, Thượng tướng Tô Lâm, Bộ trưởng Bộ Công an đã có buổi tiếp ngài Akif Ayhan, Đại sứ đặc mệnh toàn quyền Cộng hòa Thổ Nhĩ Kỳ tại Việt Nam.', 'spos': [63, 209], 'entity_1': {'text': 'Tô Lâm', 'pos': [25, 31], 'pos_no_space': [21, 26]}, 'entity_2': {'text': 'Bộ Công an', 'pos': [43, 53], 'pos_no_space': [35, 43]}, 'label': 'AFFILIATION', 'word_tokenize_lst': ['Chiều', '22-9', ',', 'Thượng tướng', 'Tô Lâm', ',', 'Bộ trưởng', 'Bộ', 'Công an', 'đã', 'có', 'buổi', 'tiếp', 'ngài', 'Akif Ayhan', ',', 'Đại sứ', 'đặc mệnh', 'toàn quyền', 'Cộng hòa Thổ', 'Nhĩ Kỳ', 'tại', 'Việt Nam', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 42, 'sentence': 'Công ty Dệt Pacific Crystal đã hai lần bị UBND tỉnh Hải Dương và Tổng cục Môi trường (Bộ Tài nguyên và Môi trường) xử phạt hành chính với số tiền lên đến 1,1 tỷ đồng vì vượt quy chuẩn kỹ thuật về chất thải xả ra môi trường và hứa sẽ khắc phụ hậu quả. Nhưng cho đến nay, tình trạng ô nhiễm vẫn còn tiếp diễn, khiến người dân địa phương rất bức xúc.', 'spos': [82, 428], 'entity_1': {'text': 'UBND', 'pos': [42, 46], 'pos_no_space': [33, 37]}, 'entity_2': {'text': 'tỉnh Hải Dương', 'pos': [47, 61], 'pos_no_space': [37, 49]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Công ty', 'Dệt', 'Pacific Crystal', 'đã', 'hai', 'lần', 'bị', 'UBND', 'tỉnh', 'Hải Dương', 'và', 'Tổng cục', 'Môi trường', '(', 'Bộ Tài nguyên và Môi trường', ')', 'xử phạt', 'hành chính', 'với', 'số', 'tiền', 'lên', 'đến', '1,1', 'tỷ', 'đồng', 'vì', 'vượt', 'quy chuẩn', 'kỹ thuật', 'về', 'chất thải', 'xả', 'ra', 'môi trường', 'và', 'hứa', 'sẽ', 'khắc', 'phụ', 'hậu quả', '.', 'Nhưng', 'cho', 'đến', 'nay', ',', 'tình trạng', 'ô nhiễm', 'vẫn', 'còn', 'tiếp diễn', ',', 'khiến', 'người', 'dân', 'địa phương', 'rất', 'bức xúc', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 43, 'sentence': 'Đi vào hoạt động từ năm 2015, công ty Dệt Pacific Crystal có địa chỉ tại Khu công nghiệp Lai Vu, huyện Kim Thành, Hải Dương khiến người dân địa phương bức xúc vì nạn xả nước thải gây ô nhiễm môi trường nghiêm trọng. Theo người dân, từ năm ngoái họ đã chịu mùi hôi thối rất khó chịu bốc lên từ dòng nước mà công ty Pacific Crystal xả ra môi trường, nhất là về ban đêm. Ông Vịnh, một cựu chiến binh địa phương cho biết: Mùi hôi thối bốc lên rất khó chịu, hôi hám, không thể chịu nổi.', 'spos': [429, 909], 'entity_1': {'text': 'công ty Dệt Pacific Crystal', 'pos': [30, 57], 'pos_no_space': [23, 46]}, 'entity_2': {'text': 'Khu công nghiệp Lai Vu', 'pos': [73, 95], 'pos_no_space': [57, 75]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Đi', 'vào', 'hoạt động', 'từ', 'năm', '2015', ',', 'công ty', 'Dệt Pacific Crystal', 'có', 'địa chỉ', 'tại', 'Khu công nghiệp', 'Lai Vu', ',', 'huyện', 'Kim Thành', ',', 'Hải Dương', 'khiến', 'người', 'dân', 'địa phương', 'bức xúc', 'vì', 'nạn', 'xả', 'nước thải', 'gây', 'ô nhiễm', 'môi trường', 'nghiêm trọng', '.', 'Theo', 'người', 'dân', ',', 'từ', 'năm ngoái', 'họ', 'đã', 'chịu', 'mùi', 'hôi thối', 'rất', 'khó chịu', 'bốc', 'lên', 'từ', 'dòng', 'nước', 'mà', 'công ty', 'Pacific Crystal', 'xả', 'ra', 'môi trường', ',', 'nhất là', 'về', 'ban đêm', '.', 'Ông', 'Vịnh', ',', 'một', 'cựu chiến binh', 'địa phương', 'cho', 'biết', ':', 'Mùi', 'hôi thối', 'bốc', 'lên', 'rất', 'khó chịu', ',', 'hôi hám', ',', 'không thể', 'chịu', 'nổi', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 44, 'sentence': 'Đi vào hoạt động từ năm 2015, công ty Dệt Pacific Crystal có địa chỉ tại Khu công nghiệp Lai Vu, huyện Kim Thành, Hải Dương khiến người dân địa phương bức xúc vì nạn xả nước thải gây ô nhiễm môi trường nghiêm trọng. Theo người dân, từ năm ngoái họ đã chịu mùi hôi thối rất khó chịu bốc lên từ dòng nước mà công ty Pacific Crystal xả ra môi trường, nhất là về ban đêm. Ông Vịnh, một cựu chiến binh địa phương cho biết: Mùi hôi thối bốc lên rất khó chịu, hôi hám, không thể chịu nổi.', 'spos': [429, 909], 'entity_1': {'text': 'công ty Dệt Pacific Crystal', 'pos': [30, 57], 'pos_no_space': [23, 46]}, 'entity_2': {'text': 'huyện Kim Thành', 'pos': [97, 112], 'pos_no_space': [76, 89]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Đi', 'vào', 'hoạt động', 'từ', 'năm', '2015', ',', 'công ty', 'Dệt Pacific Crystal', 'có', 'địa chỉ', 'tại', 'Khu công nghiệp', 'Lai Vu', ',', 'huyện', 'Kim Thành', ',', 'Hải Dương', 'khiến', 'người', 'dân', 'địa phương', 'bức xúc', 'vì', 'nạn', 'xả', 'nước thải', 'gây', 'ô nhiễm', 'môi trường', 'nghiêm trọng', '.', 'Theo', 'người', 'dân', ',', 'từ', 'năm ngoái', 'họ', 'đã', 'chịu', 'mùi', 'hôi thối', 'rất', 'khó chịu', 'bốc', 'lên', 'từ', 'dòng', 'nước', 'mà', 'công ty', 'Pacific Crystal', 'xả', 'ra', 'môi trường', ',', 'nhất là', 'về', 'ban đêm', '.', 'Ông', 'Vịnh', ',', 'một', 'cựu chiến binh', 'địa phương', 'cho', 'biết', ':', 'Mùi', 'hôi thối', 'bốc', 'lên', 'rất', 'khó chịu', ',', 'hôi hám', ',', 'không thể', 'chịu', 'nổi', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 45, 'sentence': 'Đi vào hoạt động từ năm 2015, công ty Dệt Pacific Crystal có địa chỉ tại Khu công nghiệp Lai Vu, huyện Kim Thành, Hải Dương khiến người dân địa phương bức xúc vì nạn xả nước thải gây ô nhiễm môi trường nghiêm trọng. Theo người dân, từ năm ngoái họ đã chịu mùi hôi thối rất khó chịu bốc lên từ dòng nước mà công ty Pacific Crystal xả ra môi trường, nhất là về ban đêm. Ông Vịnh, một cựu chiến binh địa phương cho biết: Mùi hôi thối bốc lên rất khó chịu, hôi hám, không thể chịu nổi.', 'spos': [429, 909], 'entity_1': {'text': 'công ty Dệt Pacific Crystal', 'pos': [30, 57], 'pos_no_space': [23, 46]}, 'entity_2': {'text': 'Hải Dương', 'pos': [114, 123], 'pos_no_space': [90, 98]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Đi', 'vào', 'hoạt động', 'từ', 'năm', '2015', ',', 'công ty', 'Dệt Pacific Crystal', 'có', 'địa chỉ', 'tại', 'Khu công nghiệp', 'Lai Vu', ',', 'huyện', 'Kim Thành', ',', 'Hải Dương', 'khiến', 'người', 'dân', 'địa phương', 'bức xúc', 'vì', 'nạn', 'xả', 'nước thải', 'gây', 'ô nhiễm', 'môi trường', 'nghiêm trọng', '.', 'Theo', 'người', 'dân', ',', 'từ', 'năm ngoái', 'họ', 'đã', 'chịu', 'mùi', 'hôi thối', 'rất', 'khó chịu', 'bốc', 'lên', 'từ', 'dòng', 'nước', 'mà', 'công ty', 'Pacific Crystal', 'xả', 'ra', 'môi trường', ',', 'nhất là', 'về', 'ban đêm', '.', 'Ông', 'Vịnh', ',', 'một', 'cựu chiến binh', 'địa phương', 'cho', 'biết', ':', 'Mùi', 'hôi thối', 'bốc', 'lên', 'rất', 'khó chịu', ',', 'hôi hám', ',', 'không thể', 'chịu', 'nổi', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 46, 'sentence': 'Đi vào hoạt động từ năm 2015, công ty Dệt Pacific Crystal có địa chỉ tại Khu công nghiệp Lai Vu, huyện Kim Thành, Hải Dương khiến người dân địa phương bức xúc vì nạn xả nước thải gây ô nhiễm môi trường nghiêm trọng. Theo người dân, từ năm ngoái họ đã chịu mùi hôi thối rất khó chịu bốc lên từ dòng nước mà công ty Pacific Crystal xả ra môi trường, nhất là về ban đêm. Ông Vịnh, một cựu chiến binh địa phương cho biết: Mùi hôi thối bốc lên rất khó chịu, hôi hám, không thể chịu nổi.', 'spos': [429, 909], 'entity_1': {'text': 'Khu công nghiệp Lai Vu', 'pos': [73, 95], 'pos_no_space': [57, 75]}, 'entity_2': {'text': 'huyện Kim Thành', 'pos': [97, 112], 'pos_no_space': [76, 89]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Đi', 'vào', 'hoạt động', 'từ', 'năm', '2015', ',', 'công ty', 'Dệt Pacific Crystal', 'có', 'địa chỉ', 'tại', 'Khu công nghiệp', 'Lai Vu', ',', 'huyện', 'Kim Thành', ',', 'Hải Dương', 'khiến', 'người', 'dân', 'địa phương', 'bức xúc', 'vì', 'nạn', 'xả', 'nước thải', 'gây', 'ô nhiễm', 'môi trường', 'nghiêm trọng', '.', 'Theo', 'người', 'dân', ',', 'từ', 'năm ngoái', 'họ', 'đã', 'chịu', 'mùi', 'hôi thối', 'rất', 'khó chịu', 'bốc', 'lên', 'từ', 'dòng', 'nước', 'mà', 'công ty', 'Pacific Crystal', 'xả', 'ra', 'môi trường', ',', 'nhất là', 'về', 'ban đêm', '.', 'Ông', 'Vịnh', ',', 'một', 'cựu chiến binh', 'địa phương', 'cho', 'biết', ':', 'Mùi', 'hôi thối', 'bốc', 'lên', 'rất', 'khó chịu', ',', 'hôi hám', ',', 'không thể', 'chịu', 'nổi', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 47, 'sentence': 'Đi vào hoạt động từ năm 2015, công ty Dệt Pacific Crystal có địa chỉ tại Khu công nghiệp Lai Vu, huyện Kim Thành, Hải Dương khiến người dân địa phương bức xúc vì nạn xả nước thải gây ô nhiễm môi trường nghiêm trọng. Theo người dân, từ năm ngoái họ đã chịu mùi hôi thối rất khó chịu bốc lên từ dòng nước mà công ty Pacific Crystal xả ra môi trường, nhất là về ban đêm. Ông Vịnh, một cựu chiến binh địa phương cho biết: Mùi hôi thối bốc lên rất khó chịu, hôi hám, không thể chịu nổi.', 'spos': [429, 909], 'entity_1': {'text': 'Khu công nghiệp Lai Vu', 'pos': [73, 95], 'pos_no_space': [57, 75]}, 'entity_2': {'text': 'Hải Dương', 'pos': [114, 123], 'pos_no_space': [90, 98]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Đi', 'vào', 'hoạt động', 'từ', 'năm', '2015', ',', 'công ty', 'Dệt Pacific Crystal', 'có', 'địa chỉ', 'tại', 'Khu công nghiệp', 'Lai Vu', ',', 'huyện', 'Kim Thành', ',', 'Hải Dương', 'khiến', 'người', 'dân', 'địa phương', 'bức xúc', 'vì', 'nạn', 'xả', 'nước thải', 'gây', 'ô nhiễm', 'môi trường', 'nghiêm trọng', '.', 'Theo', 'người', 'dân', ',', 'từ', 'năm ngoái', 'họ', 'đã', 'chịu', 'mùi', 'hôi thối', 'rất', 'khó chịu', 'bốc', 'lên', 'từ', 'dòng', 'nước', 'mà', 'công ty', 'Pacific Crystal', 'xả', 'ra', 'môi trường', ',', 'nhất là', 'về', 'ban đêm', '.', 'Ông', 'Vịnh', ',', 'một', 'cựu chiến binh', 'địa phương', 'cho', 'biết', ':', 'Mùi', 'hôi thối', 'bốc', 'lên', 'rất', 'khó chịu', ',', 'hôi hám', ',', 'không thể', 'chịu', 'nổi', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 48, 'sentence': 'Đi vào hoạt động từ năm 2015, công ty Dệt Pacific Crystal có địa chỉ tại Khu công nghiệp Lai Vu, huyện Kim Thành, Hải Dương khiến người dân địa phương bức xúc vì nạn xả nước thải gây ô nhiễm môi trường nghiêm trọng. Theo người dân, từ năm ngoái họ đã chịu mùi hôi thối rất khó chịu bốc lên từ dòng nước mà công ty Pacific Crystal xả ra môi trường, nhất là về ban đêm. Ông Vịnh, một cựu chiến binh địa phương cho biết: Mùi hôi thối bốc lên rất khó chịu, hôi hám, không thể chịu nổi.', 'spos': [429, 909], 'entity_1': {'text': 'huyện Kim Thành', 'pos': [97, 112], 'pos_no_space': [76, 89]}, 'entity_2': {'text': 'Hải Dương', 'pos': [114, 123], 'pos_no_space': [90, 98]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Đi', 'vào', 'hoạt động', 'từ', 'năm', '2015', ',', 'công ty', 'Dệt Pacific Crystal', 'có', 'địa chỉ', 'tại', 'Khu công nghiệp', 'Lai Vu', ',', 'huyện', 'Kim Thành', ',', 'Hải Dương', 'khiến', 'người', 'dân', 'địa phương', 'bức xúc', 'vì', 'nạn', 'xả', 'nước thải', 'gây', 'ô nhiễm', 'môi trường', 'nghiêm trọng', '.', 'Theo', 'người', 'dân', ',', 'từ', 'năm ngoái', 'họ', 'đã', 'chịu', 'mùi', 'hôi thối', 'rất', 'khó chịu', 'bốc', 'lên', 'từ', 'dòng', 'nước', 'mà', 'công ty', 'Pacific Crystal', 'xả', 'ra', 'môi trường', ',', 'nhất là', 'về', 'ban đêm', '.', 'Ông', 'Vịnh', ',', 'một', 'cựu chiến binh', 'địa phương', 'cho', 'biết', ':', 'Mùi', 'hôi thối', 'bốc', 'lên', 'rất', 'khó chịu', ',', 'hôi hám', ',', 'không thể', 'chịu', 'nổi', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 49, 'sentence': 'Tại buổi họp báo, ông Nguyễn Hồng Sơn – Trưởng ban Tuyên giáo Tỉnh ủy Hải Dương cho biết: Tỉnh Hải Dương luôn khuyến khích và tạo điều kiện thuận lợi cho các doanh nghiệp về đầu tư tại Hải Dương, song không đánh đổi môi trường để đổi lấy tăng trưởng kinh tế. Việc để xảy ra sự cố môi trường của công ty Dệt Pacific Crystal đã khiến người dân bức xúc. Tuy nhiên, việc khắc phục sự cố môi trường là điều cần thiết và tỉnh Hải Dương tạo điều kiện tối đa cho công ty khắc phục sự cố. Nếu công ty còn để xảy ra vi phạm gây ô nhiễm môi trường sẽ đóng cửa công ty.', 'spos': [2345, 2905], 'entity_1': {'text': 'Nguyễn Hồng Sơn', 'pos': [22, 37], 'pos_no_space': [17, 30]}, 'entity_2': {'text': 'ban Tuyên giáo', 'pos': [47, 61], 'pos_no_space': [37, 49]}, 'label': 'AFFILIATION', 'word_tokenize_lst': ['Tại', 'buổi', 'họp báo', ',', 'ông', 'Nguyễn Hồng Sơn', '–', 'Trưởng', 'ban', 'Tuyên giáo', 'Tỉnh ủy', 'Hải Dương', 'cho', 'biết', ':', 'Tỉnh', 'Hải Dương', 'luôn', 'khuyến khích', 'và', 'tạo', 'điều kiện', 'thuận lợi', 'cho', 'các', 'doanh nghiệp', 'về', 'đầu tư', 'tại', 'Hải Dương', ',', 'song', 'không', 'đánh đổi', 'môi trường', 'để', 'đổi', 'lấy', 'tăng trưởng', 'kinh tế', '. Việc', 'để', 'xảy', 'ra', 'sự cố', 'môi trường', 'của', 'công ty', 'Dệt', 'Pacific Crystal', 'đã', 'khiến', 'người', 'dân', 'bức xúc', '.', 'Tuy nhiên', ',', 'việc', 'khắc phục', 'sự cố', 'môi trường', 'là', 'điều', 'cần thiết', 'và', 'tỉnh', 'Hải Dương', 'tạo', 'điều kiện', 'tối đa', 'cho', 'công ty', 'khắc phục', 'sự cố', '.', 'Nếu', 'công ty', 'còn', 'để', 'xảy', 'ra', 'vi phạm', 'gây', 'ô nhiễm', 'môi trường', 'sẽ', 'đóng', 'cửa', 'công ty', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 52, 'sentence': 'Tại buổi họp báo, ông Nguyễn Hồng Sơn – Trưởng ban Tuyên giáo Tỉnh ủy Hải Dương cho biết: Tỉnh Hải Dương luôn khuyến khích và tạo điều kiện thuận lợi cho các doanh nghiệp về đầu tư tại Hải Dương, song không đánh đổi môi trường để đổi lấy tăng trưởng kinh tế. Việc để xảy ra sự cố môi trường của công ty Dệt Pacific Crystal đã khiến người dân bức xúc. Tuy nhiên, việc khắc phục sự cố môi trường là điều cần thiết và tỉnh Hải Dương tạo điều kiện tối đa cho công ty khắc phục sự cố. Nếu công ty còn để xảy ra vi phạm gây ô nhiễm môi trường sẽ đóng cửa công ty.', 'spos': [2345, 2905], 'entity_1': {'text': 'ban Tuyên giáo', 'pos': [47, 61], 'pos_no_space': [37, 49]}, 'entity_2': {'text': 'Tỉnh ủy', 'pos': [62, 69], 'pos_no_space': [49, 55]}, 'label': 'AFFILIATION', 'word_tokenize_lst': ['Tại', 'buổi', 'họp báo', ',', 'ông', 'Nguyễn Hồng Sơn', '–', 'Trưởng', 'ban', 'Tuyên giáo', 'Tỉnh ủy', 'Hải Dương', 'cho', 'biết', ':', 'Tỉnh', 'Hải Dương', 'luôn', 'khuyến khích', 'và', 'tạo', 'điều kiện', 'thuận lợi', 'cho', 'các', 'doanh nghiệp', 'về', 'đầu tư', 'tại', 'Hải Dương', ',', 'song', 'không', 'đánh đổi', 'môi trường', 'để', 'đổi', 'lấy', 'tăng trưởng', 'kinh tế', '. Việc', 'để', 'xảy', 'ra', 'sự cố', 'môi trường', 'của', 'công ty', 'Dệt', 'Pacific Crystal', 'đã', 'khiến', 'người', 'dân', 'bức xúc', '.', 'Tuy nhiên', ',', 'việc', 'khắc phục', 'sự cố', 'môi trường', 'là', 'điều', 'cần thiết', 'và', 'tỉnh', 'Hải Dương', 'tạo', 'điều kiện', 'tối đa', 'cho', 'công ty', 'khắc phục', 'sự cố', '.', 'Nếu', 'công ty', 'còn', 'để', 'xảy', 'ra', 'vi phạm', 'gây', 'ô nhiễm', 'môi trường', 'sẽ', 'đóng', 'cửa', 'công ty', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 52, 'sentence': 'Tại buổi họp báo, ông Nguyễn Hồng Sơn – Trưởng ban Tuyên giáo Tỉnh ủy Hải Dương cho biết: Tỉnh Hải Dương luôn khuyến khích và tạo điều kiện thuận lợi cho các doanh nghiệp về đầu tư tại Hải Dương, song không đánh đổi môi trường để đổi lấy tăng trưởng kinh tế. Việc để xảy ra sự cố môi trường của công ty Dệt Pacific Crystal đã khiến người dân bức xúc. Tuy nhiên, việc khắc phục sự cố môi trường là điều cần thiết và tỉnh Hải Dương tạo điều kiện tối đa cho công ty khắc phục sự cố. Nếu công ty còn để xảy ra vi phạm gây ô nhiễm môi trường sẽ đóng cửa công ty.', 'spos': [2345, 2905], 'entity_1': {'text': 'ban Tuyên giáo', 'pos': [47, 61], 'pos_no_space': [37, 49]}, 'entity_2': {'text': 'Hải Dương', 'pos': [70, 79], 'pos_no_space': [55, 63]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Tại', 'buổi', 'họp báo', ',', 'ông', 'Nguyễn Hồng Sơn', '–', 'Trưởng', 'ban', 'Tuyên giáo', 'Tỉnh ủy', 'Hải Dương', 'cho', 'biết', ':', 'Tỉnh', 'Hải Dương', 'luôn', 'khuyến khích', 'và', 'tạo', 'điều kiện', 'thuận lợi', 'cho', 'các', 'doanh nghiệp', 'về', 'đầu tư', 'tại', 'Hải Dương', ',', 'song', 'không', 'đánh đổi', 'môi trường', 'để', 'đổi', 'lấy', 'tăng trưởng', 'kinh tế', '. Việc', 'để', 'xảy', 'ra', 'sự cố', 'môi trường', 'của', 'công ty', 'Dệt', 'Pacific Crystal', 'đã', 'khiến', 'người', 'dân', 'bức xúc', '.', 'Tuy nhiên', ',', 'việc', 'khắc phục', 'sự cố', 'môi trường', 'là', 'điều', 'cần thiết', 'và', 'tỉnh', 'Hải Dương', 'tạo', 'điều kiện', 'tối đa', 'cho', 'công ty', 'khắc phục', 'sự cố', '.', 'Nếu', 'công ty', 'còn', 'để', 'xảy', 'ra', 'vi phạm', 'gây', 'ô nhiễm', 'môi trường', 'sẽ', 'đóng', 'cửa', 'công ty', '.']}\n",
            "{'doc_id': '23352409', 'sent_id': 53, 'sentence': 'Tại buổi họp báo, ông Nguyễn Hồng Sơn – Trưởng ban Tuyên giáo Tỉnh ủy Hải Dương cho biết: Tỉnh Hải Dương luôn khuyến khích và tạo điều kiện thuận lợi cho các doanh nghiệp về đầu tư tại Hải Dương, song không đánh đổi môi trường để đổi lấy tăng trưởng kinh tế. Việc để xảy ra sự cố môi trường của công ty Dệt Pacific Crystal đã khiến người dân bức xúc. Tuy nhiên, việc khắc phục sự cố môi trường là điều cần thiết và tỉnh Hải Dương tạo điều kiện tối đa cho công ty khắc phục sự cố. Nếu công ty còn để xảy ra vi phạm gây ô nhiễm môi trường sẽ đóng cửa công ty.', 'spos': [2345, 2905], 'entity_1': {'text': 'Tỉnh ủy', 'pos': [62, 69], 'pos_no_space': [49, 55]}, 'entity_2': {'text': 'Hải Dương', 'pos': [70, 79], 'pos_no_space': [55, 63]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Tại', 'buổi', 'họp báo', ',', 'ông', 'Nguyễn Hồng Sơn', '–', 'Trưởng ban', 'Tuyên giáo', 'Tỉnh ủy', 'Hải Dương', 'cho', 'biết', ':', 'Tỉnh', 'Hải Dương', 'luôn', 'khuyến khích', 'và', 'tạo', 'điều kiện', 'thuận lợi', 'cho', 'các', 'doanh nghiệp', 'về', 'đầu tư', 'tại', 'Hải Dương', ',', 'song', 'không', 'đánh đổi', 'môi trường', 'để', 'đổi', 'lấy', 'tăng trưởng', 'kinh tế', '. Việc', 'để', 'xảy', 'ra', 'sự cố', 'môi trường', 'của', 'công ty', 'Dệt', 'Pacific Crystal', 'đã', 'khiến', 'người', 'dân', 'bức xúc', '.', 'Tuy nhiên', ',', 'việc', 'khắc phục', 'sự cố', 'môi trường', 'là', 'điều', 'cần thiết', 'và', 'tỉnh', 'Hải Dương', 'tạo', 'điều kiện', 'tối đa', 'cho', 'công ty', 'khắc phục', 'sự cố', '.', 'Nếu', 'công ty', 'còn', 'để', 'xảy', 'ra', 'vi phạm', 'gây', 'ô nhiễm', 'môi trường', 'sẽ', 'đóng', 'cửa', 'công ty', '.']}\n",
            "{'doc_id': '23352878', 'sent_id': 54, 'sentence': 'Nga phủ nhận liên quan tới các quảng cáo trên Facebook tác động bầu cử Mỹ', 'spos': [0, 73], 'entity_1': {'text': 'Nga', 'pos': [0, 3], 'pos_no_space': [0, 3]}, 'entity_2': {'text': 'Mỹ', 'pos': [71, 73], 'pos_no_space': [56, 58]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ']}\n",
            "{'doc_id': '23353706', 'sent_id': 57, 'sentence': 'Hàng trăm lượt người tham quan triển lãm về chủ quyền Hoàng Sa và Trường Sa', 'spos': [0, 75], 'entity_1': {'text': 'Hoàng Sa', 'pos': [54, 62], 'pos_no_space': [43, 50]}, 'entity_2': {'text': 'Trường Sa', 'pos': [66, 75], 'pos_no_space': [52, 60]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Hàng', 'trăm', 'lượt', 'người', 'tham quan', 'triển lãm', 'về', 'chủ quyền', 'Hoàng Sa', 'và', 'Trường Sa']}\n",
            "{'doc_id': '23353706', 'sent_id': 58, 'sentence': 'Sáng 9-12, tại xã Tam Thanh, thành phố Tam Kỳ, tỉnh Quảng Nam, Bảo tàng tỉnh Quảng Nam phối hợp với Đồn BP Tam Thanh, BĐBP tỉnh và Ủy ban nhân dân xã Tam Thanh tổ chức khai mạc triển lãm bản đồ và trưng bày tư liệu Hoàng Sa, Trường Sa của Việt Nam - những bằng chứng lịch sử và pháp lý.', 'spos': [76, 361], 'entity_1': {'text': 'xã Tam Thanh', 'pos': [15, 27], 'pos_no_space': [12, 22]}, 'entity_2': {'text': 'thành phố Tam Kỳ', 'pos': [29, 45], 'pos_no_space': [23, 36]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Sáng', '9-12', ',', 'tại', 'xã', 'Tam Thanh', ',', 'thành phố', 'Tam Kỳ', ',', 'tỉnh', 'Quảng Nam', ',', 'Bảo tàng', 'tỉnh', 'Quảng Nam', 'phối hợp', 'với', 'Đồn', 'BP', 'Tam Thanh', ',', 'BĐBP', 'tỉnh', 'và', 'Ủy ban', 'nhân dân', 'xã', 'Tam Thanh', 'tổ chức', 'khai mạc', 'triển lãm', 'bản đồ', 'và', 'trưng bày', 'tư liệu', 'Hoàng Sa', ',', 'Trường Sa', 'của', 'Việt Nam', '-', 'những', 'bằng chứng', 'lịch sử', 'và', 'pháp lý', '.']}\n",
            "{'doc_id': '23353706', 'sent_id': 59, 'sentence': 'Sáng 9-12, tại xã Tam Thanh, thành phố Tam Kỳ, tỉnh Quảng Nam, Bảo tàng tỉnh Quảng Nam phối hợp với Đồn BP Tam Thanh, BĐBP tỉnh và Ủy ban nhân dân xã Tam Thanh tổ chức khai mạc triển lãm bản đồ và trưng bày tư liệu Hoàng Sa, Trường Sa của Việt Nam - những bằng chứng lịch sử và pháp lý.', 'spos': [76, 361], 'entity_1': {'text': 'xã Tam Thanh', 'pos': [15, 27], 'pos_no_space': [12, 22]}, 'entity_2': {'text': 'tỉnh Quảng Nam', 'pos': [47, 61], 'pos_no_space': [37, 49]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Sáng', '9-12', ',', 'tại', 'xã', 'Tam Thanh', ',', 'thành phố', 'Tam Kỳ', ',', 'tỉnh', 'Quảng Nam', ',', 'Bảo tàng', 'tỉnh', 'Quảng Nam', 'phối hợp', 'với', 'Đồn', 'BP', 'Tam Thanh', ',', 'BĐBP', 'tỉnh', 'và', 'Ủy ban', 'nhân dân', 'xã', 'Tam Thanh', 'tổ chức', 'khai mạc', 'triển lãm', 'bản đồ', 'và', 'trưng bày', 'tư liệu', 'Hoàng Sa', ',', 'Trường Sa', 'của', 'Việt Nam', '-', 'những', 'bằng chứng', 'lịch sử', 'và', 'pháp lý', '.']}\n",
            "{'doc_id': '23353706', 'sent_id': 60, 'sentence': 'Sáng 9-12, tại xã Tam Thanh, thành phố Tam Kỳ, tỉnh Quảng Nam, Bảo tàng tỉnh Quảng Nam phối hợp với Đồn BP Tam Thanh, BĐBP tỉnh và Ủy ban nhân dân xã Tam Thanh tổ chức khai mạc triển lãm bản đồ và trưng bày tư liệu Hoàng Sa, Trường Sa của Việt Nam - những bằng chứng lịch sử và pháp lý.', 'spos': [76, 361], 'entity_1': {'text': 'thành phố Tam Kỳ', 'pos': [29, 45], 'pos_no_space': [23, 36]}, 'entity_2': {'text': 'tỉnh Quảng Nam', 'pos': [47, 61], 'pos_no_space': [37, 49]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Sáng', '9-12', ',', 'tại', 'xã', 'Tam Thanh', ',', 'thành phố', 'Tam Kỳ', ',', 'tỉnh', 'Quảng Nam', ',', 'Bảo tàng', 'tỉnh', 'Quảng Nam', 'phối hợp', 'với', 'Đồn', 'BP', 'Tam Thanh', ',', 'BĐBP', 'tỉnh', 'và', 'Ủy ban', 'nhân dân', 'xã', 'Tam Thanh', 'tổ chức', 'khai mạc', 'triển lãm', 'bản đồ', 'và', 'trưng bày', 'tư liệu', 'Hoàng Sa', ',', 'Trường Sa', 'của', 'Việt Nam', '-', 'những', 'bằng chứng', 'lịch sử', 'và', 'pháp lý', '.']}\n",
            "{'doc_id': '23353706', 'sent_id': 64, 'sentence': 'Sáng 9-12, tại xã Tam Thanh, thành phố Tam Kỳ, tỉnh Quảng Nam, Bảo tàng tỉnh Quảng Nam phối hợp với Đồn BP Tam Thanh, BĐBP tỉnh và Ủy ban nhân dân xã Tam Thanh tổ chức khai mạc triển lãm bản đồ và trưng bày tư liệu Hoàng Sa, Trường Sa của Việt Nam - những bằng chứng lịch sử và pháp lý.', 'spos': [76, 361], 'entity_1': {'text': 'Hoàng Sa', 'pos': [215, 223], 'pos_no_space': [167, 174]}, 'entity_2': {'text': 'Trường Sa', 'pos': [225, 234], 'pos_no_space': [175, 183]}, 'label': 'PART_WHOLE', 'word_tokenize_lst': ['Sáng', '9-12', ',', 'tại', 'xã', 'Tam Thanh', ',', 'thành phố', 'Tam Kỳ', ',', 'tỉnh', 'Quảng Nam', ',', 'Bảo tàng', 'tỉnh', 'Quảng Nam', 'phối hợp', 'với', 'Đồn', 'BP', 'Tam Thanh', ',', 'BĐBP', 'tỉnh', 'và', 'Ủy ban', 'nhân dân', 'xã', 'Tam Thanh', 'tổ chức', 'khai mạc', 'triển lãm', 'bản đồ', 'và', 'trưng bày', 'tư liệu', 'Hoàng Sa', ',', 'Trường Sa', 'của', 'Việt Nam', '-', 'những', 'bằng chứng', 'lịch sử', 'và', 'pháp lý', '.']}\n",
            "{'doc_id': '23353706', 'sent_id': 68, 'sentence': 'Tại trang An Lạc, đất Quảng An (nay là huyện Thọ Xuân, Thanh Hóa) có vợ chồng ông Nguyễn Nhân và bà Hoàng Thị, ăn ở hiền lành, tu nhân tích đức, ham làm việc thiện, chỉ hiềm nỗi mãi vẫn chưa có con.', 'spos': [196, 393], 'entity_1': {'text': 'huyện Thọ Xuân', 'pos': [39, 53], 'pos_no_space': [30, 42]}, 'entity_2': {'text': 'Thanh Hóa', 'pos': [55, 64], 'pos_no_space': [43, 51]}, 'label': 'LOCATED', 'word_tokenize_lst': ['Tại', 'trang', 'An Lạc', ',', 'đất', 'Quảng An', '(', 'nay', 'là', 'huyện', 'Thọ Xuân', ',', 'Thanh Hóa', ')', 'có', 'vợ chồng', 'ông', 'Nguyễn Nhân', 'và', 'bà Hoàng Thị', ',', 'ăn ở', 'hiền lành', ',', 'tu nhân', 'tích đức', ',', 'ham', 'làm', 'việc', 'thiện', ',', 'chỉ', 'hiềm', 'nỗi', 'mãi', 'vẫn', 'chưa', 'có', 'con', '.']}\n"
          ]
        }
      ],
      "source": [
        "# review\n",
        "predict_labels=[]\n",
        "for i in range(len(model_1_results)):\n",
        "    predict_labels.append(model_1_results[i]['label'])\n",
        "    if model_1_results[i]['label'] != 'OTHERS':\n",
        "        print(model_1_results[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEgpZSFMkqwv",
        "outputId": "f0e1466b-a92d-424c-950c-4a2d12877c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score macro\n",
            "0.32969441026089336\n",
            "accuracy\n",
            "0.4166666666666667\n"
          ]
        }
      ],
      "source": [
        "jtest_data\n",
        "print('F1-score macro')\n",
        "print(f1_score(label, predict_labels, average='macro'))\n",
        "print('accuracy')\n",
        "print(accuracy_score(label , predict_labels))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RELATION_EXTRACTION.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "087c9f75c19e4859ab007e3cd760716b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab8b4c04a9894b2aa1d2f5169d2e7831",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6c5b993859a3447bab3a1ef55df5f65f",
              "IPY_MODEL_36b78dd5800341c691465272cd2852e7",
              "IPY_MODEL_69c4956c1f274184bd96a6a141cc1fce"
            ]
          }
        },
        "ab8b4c04a9894b2aa1d2f5169d2e7831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c5b993859a3447bab3a1ef55df5f65f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_de3e27c8b75341f1a9f24f302a59f0ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b58d3d2d0ca41858aa22ee00d8cc87d"
          }
        },
        "36b78dd5800341c691465272cd2852e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_565a78cf18344b5481621920e15aa1f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 557,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 557,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1afe3e490abc461b80301ca86fb83f8e"
          }
        },
        "69c4956c1f274184bd96a6a141cc1fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9fb0165c881f48379879393b2f87b03a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 557/557 [00:00&lt;00:00, 13.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93e9238fc87142dc8db18815b5584576"
          }
        },
        "de3e27c8b75341f1a9f24f302a59f0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b58d3d2d0ca41858aa22ee00d8cc87d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "565a78cf18344b5481621920e15aa1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1afe3e490abc461b80301ca86fb83f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fb0165c881f48379879393b2f87b03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93e9238fc87142dc8db18815b5584576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "428a3d910dd04e128c4712dbe6e0e1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0529d09c36f04b07a5e10a24981dcc0a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aa039e38fac64b589c26cd5bd2d710ac",
              "IPY_MODEL_ca7956fa69bb4e329966fbd159a0b13a",
              "IPY_MODEL_aaace6a4fb4749e28a9435cc81350a5e"
            ]
          }
        },
        "0529d09c36f04b07a5e10a24981dcc0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa039e38fac64b589c26cd5bd2d710ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_04711edee7194914aef9b741c6cb4517",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a49f3ac536184819bb0139a978e3fbc6"
          }
        },
        "ca7956fa69bb4e329966fbd159a0b13a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb1d95abb9a84189b1f2f1eb9a4e4076",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 895321,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 895321,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac6de59ae71b4b9a8561abcff7d8b8f4"
          }
        },
        "aaace6a4fb4749e28a9435cc81350a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8365eb5207c40bd99bb5080ee14c6f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 874k/874k [00:00&lt;00:00, 962kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdb1e6e5584e48469e91d67515e76c06"
          }
        },
        "04711edee7194914aef9b741c6cb4517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a49f3ac536184819bb0139a978e3fbc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb1d95abb9a84189b1f2f1eb9a4e4076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac6de59ae71b4b9a8561abcff7d8b8f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8365eb5207c40bd99bb5080ee14c6f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdb1e6e5584e48469e91d67515e76c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b385132100a4e548f19ab6ff939518c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b32525bfe39344ab9fb664173740bbad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90b8078798cb4e369ef23b17ed5c60a2",
              "IPY_MODEL_ad8da13a006d4fd1b94fb929c9639779",
              "IPY_MODEL_64d068395b1b4b7cb84c71bb1b1bd9b5"
            ]
          }
        },
        "b32525bfe39344ab9fb664173740bbad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90b8078798cb4e369ef23b17ed5c60a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8e9e3d26c824308ab9e17542cd54fe0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6367adf606ca44c29960ca34eb747f3c"
          }
        },
        "ad8da13a006d4fd1b94fb929c9639779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94c7c9aea515475ea83ac07f7f0174f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1135173,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1135173,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96acf949f1244f098bea61647741d072"
          }
        },
        "64d068395b1b4b7cb84c71bb1b1bd9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6abb078571254917adbb4874ba08baa5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.08M/1.08M [00:00&lt;00:00, 928kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_001b4f1f0ea54f8ba642f39722a2aedc"
          }
        },
        "e8e9e3d26c824308ab9e17542cd54fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6367adf606ca44c29960ca34eb747f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94c7c9aea515475ea83ac07f7f0174f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96acf949f1244f098bea61647741d072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6abb078571254917adbb4874ba08baa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "001b4f1f0ea54f8ba642f39722a2aedc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d292dd6d0cf4cb9af8794f7e2bd3552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2eb990f696894f479c1b2a9e9dc069b0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7eb9d5cc0d3b49fab9df80df46e93252",
              "IPY_MODEL_ce5aeb0a0e0d4dc68331141aa135288a",
              "IPY_MODEL_40cbf7bb5e2b4d3486b12009020b521f"
            ]
          }
        },
        "2eb990f696894f479c1b2a9e9dc069b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7eb9d5cc0d3b49fab9df80df46e93252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_108db016f2ac451887b55b76be989ae8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cac60f1d5d49415ba2cd9a9650700d6d"
          }
        },
        "ce5aeb0a0e0d4dc68331141aa135288a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_206efd6aad5042ba89d31560bf79ea31",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 542923308,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 542923308,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80309b7d2cd44aecb125e26b7033dd04"
          }
        },
        "40cbf7bb5e2b4d3486b12009020b521f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d05364a395a344cd862a7f59699fdc0d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 518M/518M [00:34&lt;00:00, 30.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08e54cac8eb84b0ca20a10c7982da1e4"
          }
        },
        "108db016f2ac451887b55b76be989ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cac60f1d5d49415ba2cd9a9650700d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "206efd6aad5042ba89d31560bf79ea31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80309b7d2cd44aecb125e26b7033dd04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d05364a395a344cd862a7f59699fdc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08e54cac8eb84b0ca20a10c7982da1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}